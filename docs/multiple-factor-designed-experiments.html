<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Multiple Factor Designed Experiments | Introduction to Statistical Modeling</title>
  <meta name="description" content="Covers Regression and elements of Design of Experiments in R using the tidyverse." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Multiple Factor Designed Experiments | Introduction to Statistical Modeling" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Covers Regression and elements of Design of Experiments in R using the tidyverse." />
  <meta name="github-repo" content="tjfisher19/introStatModeling" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Multiple Factor Designed Experiments | Introduction to Statistical Modeling" />
  
  <meta name="twitter:description" content="Covers Regression and elements of Design of Experiments in R using the tidyverse." />
  

<meta name="author" content="Michael R. Hughes and Thomas J. Fisher" />


<meta name="date" content="2022-01-09" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="introduction-to-statistical-modeling-and-designed-experiments.html"/>
<link rel="next" href="advanced-designs.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Inroduction to Statistical Modeling</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="" data-path="about-the-authors.html"><a href="about-the-authors.html"><i class="fa fa-check"></i>About the Authors</a></li>
<li class="chapter" data-level="" data-path="important-preliminary-review.html"><a href="important-preliminary-review.html"><i class="fa fa-check"></i>Important Preliminary Review</a>
<ul>
<li class="chapter" data-level="" data-path="important-preliminary-review.html"><a href="important-preliminary-review.html#statistics-background"><i class="fa fa-check"></i>Statistics background</a></li>
<li class="chapter" data-level="" data-path="important-preliminary-review.html"><a href="important-preliminary-review.html#software"><i class="fa fa-check"></i>Software</a></li>
<li class="chapter" data-level="" data-path="important-preliminary-review.html"><a href="important-preliminary-review.html#add-on-packages"><i class="fa fa-check"></i>Add-on packages</a></li>
<li class="chapter" data-level="" data-path="important-preliminary-review.html"><a href="important-preliminary-review.html#help-with-rmarkdown"><i class="fa fa-check"></i>Help with RMarkdown</a></li>
<li class="chapter" data-level="" data-path="important-preliminary-review.html"><a href="important-preliminary-review.html#managing-your-work-in-r"><i class="fa fa-check"></i>Managing your work in R</a></li>
<li class="chapter" data-level="" data-path="important-preliminary-review.html"><a href="important-preliminary-review.html#data-in-this-text"><i class="fa fa-check"></i>Data in this text</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introductory-statistics-in-r.html"><a href="introductory-statistics-in-r.html"><i class="fa fa-check"></i><b>1</b> Introductory Statistics in R</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introductory-statistics-in-r.html"><a href="introductory-statistics-in-r.html#goals-of-a-statistical-analysis"><i class="fa fa-check"></i><b>1.1</b> Goals of a statistical analysis</a></li>
<li class="chapter" data-level="1.2" data-path="introductory-statistics-in-r.html"><a href="introductory-statistics-in-r.html#before-you-begin-an-analysis"><i class="fa fa-check"></i><b>1.2</b> Before you begin an analysis</a></li>
<li class="chapter" data-level="1.3" data-path="introductory-statistics-in-r.html"><a href="introductory-statistics-in-r.html#data-frames"><i class="fa fa-check"></i><b>1.3</b> Data frames</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="introductory-statistics-in-r.html"><a href="introductory-statistics-in-r.html#built-in-data"><i class="fa fa-check"></i><b>1.3.1</b> Built-in data</a></li>
<li class="chapter" data-level="1.3.2" data-path="introductory-statistics-in-r.html"><a href="introductory-statistics-in-r.html#types-of-data"><i class="fa fa-check"></i><b>1.3.2</b> Types of Data</a></li>
<li class="chapter" data-level="1.3.3" data-path="introductory-statistics-in-r.html"><a href="introductory-statistics-in-r.html#importing-datasets-into-r"><i class="fa fa-check"></i><b>1.3.3</b> Importing datasets into R</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="introductory-statistics-in-r.html"><a href="introductory-statistics-in-r.html#referencing-data-from-inside-a-data-frame"><i class="fa fa-check"></i><b>1.4</b> Referencing data from inside a data frame</a></li>
<li class="chapter" data-level="1.5" data-path="introductory-statistics-in-r.html"><a href="introductory-statistics-in-r.html#missing-values-and-computer-arithmetic-in-r"><i class="fa fa-check"></i><b>1.5</b> Missing values and computer arithmetic in R</a></li>
<li class="chapter" data-level="1.6" data-path="introductory-statistics-in-r.html"><a href="introductory-statistics-in-r.html#exploratory-data-analysis-eda"><i class="fa fa-check"></i><b>1.6</b> Exploratory Data Analysis (EDA)</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="introductory-statistics-in-r.html"><a href="introductory-statistics-in-r.html#numeric-summaries"><i class="fa fa-check"></i><b>1.6.1</b> Numeric Summaries</a></li>
<li class="chapter" data-level="1.6.2" data-path="introductory-statistics-in-r.html"><a href="introductory-statistics-in-r.html#numeric-summaries-in-r"><i class="fa fa-check"></i><b>1.6.2</b> Numeric Summaries in R</a></li>
<li class="chapter" data-level="1.6.3" data-path="introductory-statistics-in-r.html"><a href="introductory-statistics-in-r.html#graphical-summaries"><i class="fa fa-check"></i><b>1.6.3</b> Graphical Summaries</a></li>
<li class="chapter" data-level="1.6.4" data-path="introductory-statistics-in-r.html"><a href="introductory-statistics-in-r.html#distribution-of-univariate-variables"><i class="fa fa-check"></i><b>1.6.4</b> Distribution of Univariate Variables</a></li>
<li class="chapter" data-level="1.6.5" data-path="introductory-statistics-in-r.html"><a href="introductory-statistics-in-r.html#descriptive-statistics-and-visualizations-by-levels-of-a-factor-variable"><i class="fa fa-check"></i><b>1.6.5</b> Descriptive statistics and visualizations by levels of a factor variable</a></li>
<li class="chapter" data-level="1.6.6" data-path="introductory-statistics-in-r.html"><a href="introductory-statistics-in-r.html#descriptive-statistics-and-visualizations-for-two-numeric-variables"><i class="fa fa-check"></i><b>1.6.6</b> Descriptive statistics and visualizations for two numeric variables</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="introductory-statistics-in-r.html"><a href="introductory-statistics-in-r.html#sampling-distributions-describing-how-a-statistic-varies"><i class="fa fa-check"></i><b>1.7</b> Sampling distributions: describing how a statistic varies</a></li>
<li class="chapter" data-level="1.8" data-path="introductory-statistics-in-r.html"><a href="introductory-statistics-in-r.html#two-sample-inference"><i class="fa fa-check"></i><b>1.8</b> Two-sample inference</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduction-to-statistical-modeling-and-designed-experiments.html"><a href="introduction-to-statistical-modeling-and-designed-experiments.html"><i class="fa fa-check"></i><b>2</b> Introduction to Statistical Modeling and Designed Experiments</a>
<ul>
<li class="chapter" data-level="2.1" data-path="introduction-to-statistical-modeling-and-designed-experiments.html"><a href="introduction-to-statistical-modeling-and-designed-experiments.html#statistical-analyses-is-modeling"><i class="fa fa-check"></i><b>2.1</b> Statistical Analyses is Modeling</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="introduction-to-statistical-modeling-and-designed-experiments.html"><a href="introduction-to-statistical-modeling-and-designed-experiments.html#example-of-a-two-sample-t-test-as-a-model"><i class="fa fa-check"></i><b>2.1.1</b> Example of a two-sample <span class="math inline">\(t\)</span>-test as a model</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="introduction-to-statistical-modeling-and-designed-experiments.html"><a href="introduction-to-statistical-modeling-and-designed-experiments.html#observational-studies-versus-designed-experiments"><i class="fa fa-check"></i><b>2.2</b> Observational Studies versus designed experiments</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="introduction-to-statistical-modeling-and-designed-experiments.html"><a href="introduction-to-statistical-modeling-and-designed-experiments.html#observational-studies"><i class="fa fa-check"></i><b>2.2.1</b> Observational Studies</a></li>
<li class="chapter" data-level="2.2.2" data-path="introduction-to-statistical-modeling-and-designed-experiments.html"><a href="introduction-to-statistical-modeling-and-designed-experiments.html#designed-experiments"><i class="fa fa-check"></i><b>2.2.2</b> Designed experiments</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="introduction-to-statistical-modeling-and-designed-experiments.html"><a href="introduction-to-statistical-modeling-and-designed-experiments.html#designed-experiement-vocabulary"><i class="fa fa-check"></i><b>2.3</b> Designed experiement vocabulary</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="introduction-to-statistical-modeling-and-designed-experiments.html"><a href="introduction-to-statistical-modeling-and-designed-experiments.html#what-is-an-experiment"><i class="fa fa-check"></i><b>2.3.1</b> What is an experiment?</a></li>
<li class="chapter" data-level="2.3.2" data-path="introduction-to-statistical-modeling-and-designed-experiments.html"><a href="introduction-to-statistical-modeling-and-designed-experiments.html#analysis-of-variance"><i class="fa fa-check"></i><b>2.3.2</b> Analysis of variance</a></li>
<li class="chapter" data-level="2.3.3" data-path="introduction-to-statistical-modeling-and-designed-experiments.html"><a href="introduction-to-statistical-modeling-and-designed-experiments.html#elements-of-a-designed-experiment"><i class="fa fa-check"></i><b>2.3.3</b> Elements of a designed experiment</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="introduction-to-statistical-modeling-and-designed-experiments.html"><a href="introduction-to-statistical-modeling-and-designed-experiments.html#paired-t-test"><i class="fa fa-check"></i><b>2.4</b> Paired <span class="math inline">\(t\)</span>-test</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="introduction-to-statistical-modeling-and-designed-experiments.html"><a href="introduction-to-statistical-modeling-and-designed-experiments.html#paired-t-test-example"><i class="fa fa-check"></i><b>2.4.1</b> Paired <span class="math inline">\(t\)</span>-test example</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="introduction-to-statistical-modeling-and-designed-experiments.html"><a href="introduction-to-statistical-modeling-and-designed-experiments.html#one-way-anova"><i class="fa fa-check"></i><b>2.5</b> One-Way ANOVA</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="introduction-to-statistical-modeling-and-designed-experiments.html"><a href="introduction-to-statistical-modeling-and-designed-experiments.html#example-of-one-way-anova"><i class="fa fa-check"></i><b>2.5.1</b> Example of One-Way ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="introduction-to-statistical-modeling-and-designed-experiments.html"><a href="introduction-to-statistical-modeling-and-designed-experiments.html#assumptionCheck"><i class="fa fa-check"></i><b>2.6</b> Assumption Checking</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="introduction-to-statistical-modeling-and-designed-experiments.html"><a href="introduction-to-statistical-modeling-and-designed-experiments.html#independence"><i class="fa fa-check"></i><b>2.6.1</b> Independence</a></li>
<li class="chapter" data-level="2.6.2" data-path="introduction-to-statistical-modeling-and-designed-experiments.html"><a href="introduction-to-statistical-modeling-and-designed-experiments.html#constant-variance"><i class="fa fa-check"></i><b>2.6.2</b> Constant Variance</a></li>
<li class="chapter" data-level="2.6.3" data-path="introduction-to-statistical-modeling-and-designed-experiments.html"><a href="introduction-to-statistical-modeling-and-designed-experiments.html#checking-normality"><i class="fa fa-check"></i><b>2.6.3</b> Checking Normality</a></li>
<li class="chapter" data-level="2.6.4" data-path="introduction-to-statistical-modeling-and-designed-experiments.html"><a href="introduction-to-statistical-modeling-and-designed-experiments.html#code-to-check-assumptions"><i class="fa fa-check"></i><b>2.6.4</b> Code to check assumptions</a></li>
<li class="chapter" data-level="2.6.5" data-path="introduction-to-statistical-modeling-and-designed-experiments.html"><a href="introduction-to-statistical-modeling-and-designed-experiments.html#transforming-your-response"><i class="fa fa-check"></i><b>2.6.5</b> Transforming your response</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="introduction-to-statistical-modeling-and-designed-experiments.html"><a href="introduction-to-statistical-modeling-and-designed-experiments.html#follow-up-procedures-multiple-comparisons"><i class="fa fa-check"></i><b>2.7</b> Follow-up procedures – Multiple Comparisons</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="introduction-to-statistical-modeling-and-designed-experiments.html"><a href="introduction-to-statistical-modeling-and-designed-experiments.html#tukeys-hsd-method"><i class="fa fa-check"></i><b>2.7.1</b> Tukey’s HSD method</a></li>
<li class="chapter" data-level="2.7.2" data-path="introduction-to-statistical-modeling-and-designed-experiments.html"><a href="introduction-to-statistical-modeling-and-designed-experiments.html#dunnett-multiple-comparisons"><i class="fa fa-check"></i><b>2.7.2</b> Dunnett multiple comparisons</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="multiple-factor-designed-experiments.html"><a href="multiple-factor-designed-experiments.html"><i class="fa fa-check"></i><b>3</b> Multiple Factor Designed Experiments</a>
<ul>
<li class="chapter" data-level="3.1" data-path="multiple-factor-designed-experiments.html"><a href="multiple-factor-designed-experiments.html#blocking"><i class="fa fa-check"></i><b>3.1</b> Blocking</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="multiple-factor-designed-experiments.html"><a href="multiple-factor-designed-experiments.html#data-structure-model-form-and-analysis-of-variance-of-a-randomized-block-design"><i class="fa fa-check"></i><b>3.1.1</b> Data structure, model form and analysis of variance of a Randomized Block Design</a></li>
<li class="chapter" data-level="3.1.2" data-path="multiple-factor-designed-experiments.html"><a href="multiple-factor-designed-experiments.html#block-anova-example"><i class="fa fa-check"></i><b>3.1.2</b> Block ANOVA Example</a></li>
<li class="chapter" data-level="3.1.3" data-path="multiple-factor-designed-experiments.html"><a href="multiple-factor-designed-experiments.html#another-block-anova-example"><i class="fa fa-check"></i><b>3.1.3</b> Another Block ANOVA Example</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="multiple-factor-designed-experiments.html"><a href="multiple-factor-designed-experiments.html#two-factor-designs"><i class="fa fa-check"></i><b>3.2</b> Two-factor Designs</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="multiple-factor-designed-experiments.html"><a href="multiple-factor-designed-experiments.html#analysis-of-a-two-factor-design"><i class="fa fa-check"></i><b>3.2.1</b> Analysis of a two-factor design</a></li>
<li class="chapter" data-level="3.2.2" data-path="multiple-factor-designed-experiments.html"><a href="multiple-factor-designed-experiments.html#example-with-no-interaction"><i class="fa fa-check"></i><b>3.2.2</b> Example with No Interaction</a></li>
<li class="chapter" data-level="3.2.3" data-path="multiple-factor-designed-experiments.html"><a href="multiple-factor-designed-experiments.html#example-with-interaction"><i class="fa fa-check"></i><b>3.2.3</b> Example with Interaction</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="advanced-designs.html"><a href="advanced-designs.html"><i class="fa fa-check"></i><b>4</b> Advanced Designs</a>
<ul>
<li class="chapter" data-level="4.1" data-path="advanced-designs.html"><a href="advanced-designs.html#higher-order-factor-models"><i class="fa fa-check"></i><b>4.1</b> Higher order factor models</a></li>
<li class="chapter" data-level="4.2" data-path="advanced-designs.html"><a href="advanced-designs.html#within-subject-designs"><i class="fa fa-check"></i><b>4.2</b> Within-subject designs</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="advanced-designs.html"><a href="advanced-designs.html#blocks-revisited-an-approach-to-handling-within-subjects-factors"><i class="fa fa-check"></i><b>4.2.1</b> Blocks revisited: an approach to handling within-subjects factors</a></li>
<li class="chapter" data-level="4.2.2" data-path="advanced-designs.html"><a href="advanced-designs.html#a-more-involved-repeated-measures-case-study"><i class="fa fa-check"></i><b>4.2.2</b> A more involved repeated measures case study</a></li>
<li class="chapter" data-level="4.2.3" data-path="advanced-designs.html"><a href="advanced-designs.html#further-study"><i class="fa fa-check"></i><b>4.2.3</b> Further study</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="introduction-to-multiple-regression.html"><a href="introduction-to-multiple-regression.html"><i class="fa fa-check"></i><b>5</b> Introduction to Multiple Regression</a>
<ul>
<li class="chapter" data-level="5.1" data-path="introduction-to-multiple-regression.html"><a href="introduction-to-multiple-regression.html#regression-model"><i class="fa fa-check"></i><b>5.1</b> Regression Model</a></li>
<li class="chapter" data-level="5.2" data-path="introduction-to-multiple-regression.html"><a href="introduction-to-multiple-regression.html#fitting-a-regression-model"><i class="fa fa-check"></i><b>5.2</b> Fitting a regression model</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="introduction-to-multiple-regression.html"><a href="introduction-to-multiple-regression.html#multiple-regression-example"><i class="fa fa-check"></i><b>5.2.1</b> Multiple Regression Example</a></li>
<li class="chapter" data-level="5.2.2" data-path="introduction-to-multiple-regression.html"><a href="introduction-to-multiple-regression.html#why-should-we-use-more-than-one-predictor"><i class="fa fa-check"></i><b>5.2.2</b> Why should we use more than one predictor?</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="introduction-to-multiple-regression.html"><a href="introduction-to-multiple-regression.html#interpreting-beta-parameter-estimates-in-mlr"><i class="fa fa-check"></i><b>5.3</b> Interpreting <span class="math inline">\(\beta\)</span>-parameter estimates in MLR</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="introduction-to-multiple-regression.html"><a href="introduction-to-multiple-regression.html#designed-experiments-1"><i class="fa fa-check"></i><b>5.3.1</b> Designed experiments</a></li>
<li class="chapter" data-level="5.3.2" data-path="introduction-to-multiple-regression.html"><a href="introduction-to-multiple-regression.html#observational-studies-1"><i class="fa fa-check"></i><b>5.3.2</b> Observational studies</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="inference-regarding-multiple-regression.html"><a href="inference-regarding-multiple-regression.html"><i class="fa fa-check"></i><b>6</b> Inference regarding Multiple Regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="inference-regarding-multiple-regression.html"><a href="inference-regarding-multiple-regression.html#assumption-checking"><i class="fa fa-check"></i><b>6.1</b> Assumption checking</a></li>
<li class="chapter" data-level="6.2" data-path="inference-regarding-multiple-regression.html"><a href="inference-regarding-multiple-regression.html#overall-f-test-for-model-signifance"><i class="fa fa-check"></i><b>6.2</b> Overall <span class="math inline">\(F\)</span>-test for model signifance</a></li>
<li class="chapter" data-level="6.3" data-path="inference-regarding-multiple-regression.html"><a href="inference-regarding-multiple-regression.html#individual-parameter-inference"><i class="fa fa-check"></i><b>6.3</b> Individual parameter inference</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="inference-regarding-multiple-regression.html"><a href="inference-regarding-multiple-regression.html#t-tests"><i class="fa fa-check"></i><b>6.3.1</b> <span class="math inline">\(t\)</span>-tests</a></li>
<li class="chapter" data-level="6.3.2" data-path="inference-regarding-multiple-regression.html"><a href="inference-regarding-multiple-regression.html#confidence-intervals"><i class="fa fa-check"></i><b>6.3.2</b> Confidence Intervals</a></li>
<li class="chapter" data-level="6.3.3" data-path="inference-regarding-multiple-regression.html"><a href="inference-regarding-multiple-regression.html#confidence-and-prediction-bands"><i class="fa fa-check"></i><b>6.3.3</b> Confidence and prediction bands</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="inference-regarding-multiple-regression.html"><a href="inference-regarding-multiple-regression.html#goodness-of-fit"><i class="fa fa-check"></i><b>6.4</b> Goodness-of-fit</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="inference-regarding-multiple-regression.html"><a href="inference-regarding-multiple-regression.html#coefficient-of-determination"><i class="fa fa-check"></i><b>6.4.1</b> Coefficient of determination</a></li>
<li class="chapter" data-level="6.4.2" data-path="inference-regarding-multiple-regression.html"><a href="inference-regarding-multiple-regression.html#akaikes-information-criterion"><i class="fa fa-check"></i><b>6.4.2</b> Akaike’s Information Criterion</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="more-on-multiple-linear-regression.html"><a href="more-on-multiple-linear-regression.html"><i class="fa fa-check"></i><b>7</b> More on multiple linear regression</a>
<ul>
<li class="chapter" data-level="7.1" data-path="more-on-multiple-linear-regression.html"><a href="more-on-multiple-linear-regression.html#model-comparision-reduced-f-tests"><i class="fa fa-check"></i><b>7.1</b> Model comparision – Reduced <span class="math inline">\(F\)</span>-tests</a></li>
<li class="chapter" data-level="7.2" data-path="more-on-multiple-linear-regression.html"><a href="more-on-multiple-linear-regression.html#categorical-predictor-variables"><i class="fa fa-check"></i><b>7.2</b> Categorical Predictor Variables</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="more-on-multiple-linear-regression.html"><a href="more-on-multiple-linear-regression.html#a-qualitative-predictor-with-two-levels"><i class="fa fa-check"></i><b>7.2.1</b> A qualitative predictor with two levels</a></li>
<li class="chapter" data-level="7.2.2" data-path="more-on-multiple-linear-regression.html"><a href="more-on-multiple-linear-regression.html#a-qualitative-predictor-with-more-than-two-levels"><i class="fa fa-check"></i><b>7.2.2</b> A qualitative predictor with more than two levels</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="more-on-multiple-linear-regression.html"><a href="more-on-multiple-linear-regression.html#bridging-regression-and-designed-experiments-ancova"><i class="fa fa-check"></i><b>7.3</b> Bridging Regression and Designed Experiments – ANCOVA</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="more-on-multiple-linear-regression.html"><a href="more-on-multiple-linear-regression.html#an-ancova-example-with-a-two-level-factor"><i class="fa fa-check"></i><b>7.3.1</b> An ANCOVA example with a two-level factor</a></li>
<li class="chapter" data-level="7.3.2" data-path="more-on-multiple-linear-regression.html"><a href="more-on-multiple-linear-regression.html#ancova-with-a-multi-level-factor"><i class="fa fa-check"></i><b>7.3.2</b> ANCOVA with a multi-level factor</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="model-building-considerations.html"><a href="model-building-considerations.html"><i class="fa fa-check"></i><b>8</b> Model Building Considerations</a>
<ul>
<li class="chapter" data-level="8.1" data-path="model-building-considerations.html"><a href="model-building-considerations.html#regression-assumptions-revisited"><i class="fa fa-check"></i><b>8.1</b> Regression assumptions revisited</a></li>
<li class="chapter" data-level="8.2" data-path="model-building-considerations.html"><a href="model-building-considerations.html#violations-of-the-independence-assumption"><i class="fa fa-check"></i><b>8.2</b> Violations of the independence assumption</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="model-building-considerations.html"><a href="model-building-considerations.html#collecting-data-that-are-temporal-or-spatial-in-nature"><i class="fa fa-check"></i><b>8.2.1</b> Collecting data that are temporal or spatial in nature</a></li>
<li class="chapter" data-level="8.2.2" data-path="model-building-considerations.html"><a href="model-building-considerations.html#pseudoreplication"><i class="fa fa-check"></i><b>8.2.2</b> Pseudoreplication</a></li>
<li class="chapter" data-level="8.2.3" data-path="model-building-considerations.html"><a href="model-building-considerations.html#what-if-we-have-non-independent-errors"><i class="fa fa-check"></i><b>8.2.3</b> What if we have non-independent errors?</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="model-building-considerations.html"><a href="model-building-considerations.html#constant-variance-violations"><i class="fa fa-check"></i><b>8.3</b> Constant Variance Violations</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="model-building-considerations.html"><a href="model-building-considerations.html#box-cox-power-tranformations"><i class="fa fa-check"></i><b>8.3.1</b> Box-Cox Power Tranformations</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="model-building-considerations.html"><a href="model-building-considerations.html#normality-violations"><i class="fa fa-check"></i><b>8.4</b> Normality violations</a></li>
<li class="chapter" data-level="8.5" data-path="model-building-considerations.html"><a href="model-building-considerations.html#violations-of-the-linearity-assumption"><i class="fa fa-check"></i><b>8.5</b> Violations of the linearity assumption</a></li>
<li class="chapter" data-level="8.6" data-path="model-building-considerations.html"><a href="model-building-considerations.html#detecting-and-dealing-with-unusual-observations"><i class="fa fa-check"></i><b>8.6</b> Detecting and dealing with unusual observations</a></li>
<li class="chapter" data-level="8.7" data-path="model-building-considerations.html"><a href="model-building-considerations.html#multicollinearity"><i class="fa fa-check"></i><b>8.7</b> Multicollinearity</a></li>
<li class="chapter" data-level="8.8" data-path="model-building-considerations.html"><a href="model-building-considerations.html#standardizingPredictors"><i class="fa fa-check"></i><b>8.8</b> Scale changes</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="model-selection.html"><a href="model-selection.html"><i class="fa fa-check"></i><b>9</b> Model Selection</a>
<ul>
<li class="chapter" data-level="9.1" data-path="model-selection.html"><a href="model-selection.html#stepwise-procedures"><i class="fa fa-check"></i><b>9.1</b> Stepwise Procedures</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="model-selection.html"><a href="model-selection.html#backward-selection"><i class="fa fa-check"></i><b>9.1.1</b> Backward Selection</a></li>
<li class="chapter" data-level="9.1.2" data-path="model-selection.html"><a href="model-selection.html#forward-selection"><i class="fa fa-check"></i><b>9.1.2</b> Forward selection</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="model-selection.html"><a href="model-selection.html#best-subsets"><i class="fa fa-check"></i><b>9.2</b> Best subsets</a></li>
<li class="chapter" data-level="9.3" data-path="model-selection.html"><a href="model-selection.html#shrinkage-methods"><i class="fa fa-check"></i><b>9.3</b> Shrinkage Methods</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="model-validation.html"><a href="model-validation.html"><i class="fa fa-check"></i><b>10</b> Model Validation</a>
<ul>
<li class="chapter" data-level="10.1" data-path="model-validation.html"><a href="model-validation.html#underfitting-vs.-overfitting-models"><i class="fa fa-check"></i><b>10.1</b> Underfitting vs. Overfitting Models</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="model-validation.html"><a href="model-validation.html#the-bias-variance-trade-off"><i class="fa fa-check"></i><b>10.1.1</b> The Bias-Variance Trade-off</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="model-validation.html"><a href="model-validation.html#validation-techniques"><i class="fa fa-check"></i><b>10.2</b> Validation Techniques</a></li>
<li class="chapter" data-level="10.3" data-path="model-validation.html"><a href="model-validation.html#basic-validation-with-a-single-holdout-sample"><i class="fa fa-check"></i><b>10.3</b> Basic Validation with a single holdout sample</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="model-validation.html"><a href="model-validation.html#use-the-training-data-to-fit-and-select-models"><i class="fa fa-check"></i><b>10.3.1</b> Use the training data to fit and select models</a></li>
<li class="chapter" data-level="10.3.2" data-path="model-validation.html"><a href="model-validation.html#model-training"><i class="fa fa-check"></i><b>10.3.2</b> Model training:</a></li>
<li class="chapter" data-level="10.3.3" data-path="model-validation.html"><a href="model-validation.html#model-validation-step"><i class="fa fa-check"></i><b>10.3.3</b> Model validation step:</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="model-validation.html"><a href="model-validation.html#hold-out-sample-validation-using-caret"><i class="fa fa-check"></i><b>10.4</b> Hold-out sample validation using <code>caret</code></a></li>
<li class="chapter" data-level="10.5" data-path="model-validation.html"><a href="model-validation.html#leave-one-out-cross-validation-loocv"><i class="fa fa-check"></i><b>10.5</b> “Leave one out” Cross-Validation (LOOCV)</a></li>
<li class="chapter" data-level="10.6" data-path="model-validation.html"><a href="model-validation.html#k-fold-cross-validation"><i class="fa fa-check"></i><b>10.6</b> <span class="math inline">\(k\)</span>-fold Cross-Validation</a></li>
<li class="chapter" data-level="10.7" data-path="model-validation.html"><a href="model-validation.html#a-final-note"><i class="fa fa-check"></i><b>10.7</b> A final note</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="statistical-odds.html"><a href="statistical-odds.html"><i class="fa fa-check"></i><b>11</b> Statistical Odds</a>
<ul>
<li class="chapter" data-level="11.1" data-path="statistical-odds.html"><a href="statistical-odds.html#probability-versus-odds"><i class="fa fa-check"></i><b>11.1</b> Probability versus Odds</a></li>
<li class="chapter" data-level="11.2" data-path="statistical-odds.html"><a href="statistical-odds.html#odds-ratios"><i class="fa fa-check"></i><b>11.2</b> Odds ratios</a></li>
<li class="chapter" data-level="11.3" data-path="statistical-odds.html"><a href="statistical-odds.html#ideas-of-modeling-odds"><i class="fa fa-check"></i><b>11.3</b> Ideas of modeling odds</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>12</b> Logistic Regression</a>
<ul>
<li class="chapter" data-level="12.1" data-path="logistic-regression.html"><a href="logistic-regression.html#logistic-model"><i class="fa fa-check"></i><b>12.1</b> Logistic Model</a></li>
<li class="chapter" data-level="12.2" data-path="logistic-regression.html"><a href="logistic-regression.html#fitting-interpreting-and-assessing-a-logistic-model"><i class="fa fa-check"></i><b>12.2</b> Fitting, Interpreting and assessing a logistic model</a></li>
<li class="chapter" data-level="12.3" data-path="logistic-regression.html"><a href="logistic-regression.html#case-study---titanic-dataset"><i class="fa fa-check"></i><b>12.3</b> Case Study - Titanic Dataset</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html"><i class="fa fa-check"></i><b>13</b> Generalized Linear Models</a>
<ul>
<li class="chapter" data-level="13.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#poisson-regression"><i class="fa fa-check"></i><b>13.1</b> Poisson Regression</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#poisson-distribution"><i class="fa fa-check"></i><b>13.1.1</b> Poisson distribution</a></li>
<li class="chapter" data-level="13.1.2" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#poisson-regression-development"><i class="fa fa-check"></i><b>13.1.2</b> Poisson Regression Development</a></li>
<li class="chapter" data-level="13.1.3" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#example---tropical-cyclone-counts-in-the-north-atlantic"><i class="fa fa-check"></i><b>13.1.3</b> Example - Tropical Cyclone Counts in the North Atlantic</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#handling-overdispersion"><i class="fa fa-check"></i><b>13.2</b> Handling overdispersion</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#example-attendnace-records"><i class="fa fa-check"></i><b>13.2.1</b> Example – Attendnace Records</a></li>
<li class="chapter" data-level="13.2.2" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#incorrect-poisson-model"><i class="fa fa-check"></i><b>13.2.2</b> Incorrect Poisson Model</a></li>
<li class="chapter" data-level="13.2.3" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#a-quasi-poisson-approach"><i class="fa fa-check"></i><b>13.2.3</b> A quasi-Poisson approach</a></li>
<li class="chapter" data-level="13.2.4" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#fitting-a-negative-binomial-regression"><i class="fa fa-check"></i><b>13.2.4</b> Fitting a Negative Binomial regression</a></li>
<li class="chapter" data-level="13.2.5" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#picking-between-quasi-poisson-and-negative-binomial"><i class="fa fa-check"></i><b>13.2.5</b> Picking between Quasi-Poisson and Negative Binomial</a></li>
<li class="chapter" data-level="13.2.6" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#infererence-on-predictor-variables"><i class="fa fa-check"></i><b>13.2.6</b> Infererence on predictor variables</a></li>
<li class="chapter" data-level="13.2.7" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#plotting-fitted-model"><i class="fa fa-check"></i><b>13.2.7</b> Plotting fitted model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Statistical Modeling</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="multiple-factor-designed-experiments" class="section level1" number="3">
<h1><span class="header-section-number">Chapter 3</span> Multiple Factor Designed Experiments</h1>
<p>In the previous chapters we have seen how one variable (perhaps a factor with multiple treatments) can influence a response variable.
It should not be much of a stretch to consider the case of multiple predictor variables influencing the response.</p>
<p><strong>Example.</strong> Consider the admissions dataset with ACT scores as a response, besides the year of entry maybe a student’s home neighborhood or state could also be a predictor?</p>
<p>In this chapter we will explore two key analyses for designed experiments – a Block design and Two-factor experiment.
The learning objectives of this unit include:</p>
<ul>
<li>Understanding the structure of a multi-factor model.</li>
<li>Understanding the rationale of a block design.</li>
<li>Understanding the rationale and structure of a two-factor design.</li>
<li>Performing a full analysis involving multiple predictor variables.</li>
</ul>
<div id="blocking" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Blocking</h2>
<p>Randomized Block Designs are a bit of an odd duck.
The type of design itself is straightforward, but the analysis might seem a bit unusual.</p>
<p>The design is best described in terms of the agricultural field trials that gave birth to it.
When conducting field trials to compare plant varieties, there is concern that some areas of a field may be more fertile than others (<em>e.g.</em>, soil nutrients, access to water, shade versus sun, etc…).
For example, if one were comparing three plant varieties (call them A, B and C), it would not be a good idea to use one variety in one location (say next to a creek), another variety in a different location, and the third variety way back in another part of the field near a forest because the effects of the varieties would be confounded with the natural fertility of the land.
See Figure <a href="multiple-factor-designed-experiments.html#fig:ch3-field">3.1</a> as an example of a poorly designed experiment.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ch3-field"></span>
<img src="chap3_field.png" alt="Diagram of a poorly designed experiment that is ignoring the potential confouding factors of a creek and forest." width="318" />
<p class="caption">
Figure 3.1: Diagram of a poorly designed experiment that is ignoring the potential confouding factors of a creek and forest.
</p>
</div>
<p>The natural fertility (next to the creek, compared to next to the forest, compared to the middle) in this situation is a <strong>confounding factor</strong>.
A confounding factor is something we are not necessarily interested in, but that none the less will have an impact on our assessment of the factor of interest (<em>e.g.</em>, plant variety).</p>
<p>We could attempt to mitigate the effect of this confounding factor through randomization.
For example, suppose by random allocation the treatments are distributed as such as in Figure <a href="multiple-factor-designed-experiments.html#fig:ch3-field-random">3.2</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ch3-field-random"></span>
<img src="chap3_field_randomized.png" alt="Randomized Design that attempts to account for the confouding factors of a creek and forest." width="318" />
<p class="caption">
Figure 3.2: Randomized Design that attempts to account for the confouding factors of a creek and forest.
</p>
</div>
<p>In Figure <a href="multiple-factor-designed-experiments.html#fig:ch3-field-random">3.2</a> the treatments have been randomly assigned to the different locations in an effort to mitigate the effects of the stream and forest on land fertility.
However, by random chance we note that treatment “C” has 4 of its 6 replicates in proximity to the stream, with the remaining 2 next to the forest.
A block design looks to address this limitation of randomization when there are suspected (known) confounding effects.</p>
<p>A <strong>block</strong> is defined to be “a relatively homogeneous set of experimental material.”
This essentially means that we would like to be able to assess the treatment effects without undue influence from a contaminating or confounding factor, such as land fertility.
One way to do this would be to apply all the different treatments (<em>e.g.</em>, the three plant varieties) to the same area of the field.
Within one area (say next the creek in Figures <a href="multiple-factor-designed-experiments.html#fig:ch3-field">3.1</a> and <a href="multiple-factor-designed-experiments.html#fig:ch3-field-random">3.2</a>), we should see consistency in natural fertility levels.
Thus any differences observed in a measured response (such as crop yield) between plant varieties will not be due to variation in fertility levels, but rather due to the different plant varieties themselves.</p>
<p>A bock design is one that attempts to reduce the noise in the measured response in order to “clarify” the effect due to the treatments under study.</p>
<p>A <strong>randomized block design</strong> in the field study would be conducted in the following way:</p>
<ul>
<li>The field is divided into blocks.
<ul>
<li>In our working example we use 3 blocks for the land next to the creek, next to the forest and that in the middle.</li>
</ul></li>
<li>Each block is divided into a number of units equal to, or more than, the number of treatments.
<ul>
<li>In the example we have 6 units in each block.</li>
</ul></li>
<li>Within each block, the treatments are assigned at random so that a different treatment is applied to each unit. When all treatments are assigned at least once in each block, it is known as a “Complete” Block Design. <strong>The defining feature of the Randomized (Complete) Block Design is that each block sees each treatment at least once.</strong>
<ul>
<li>We have randomly allocated 2 replicates of each treatment in each block for a complete and balanced design.</li>
</ul></li>
</ul>
<p>Figure <a href="multiple-factor-designed-experiments.html#fig:ch3-field-block">3.3</a> displays a randomized complete block design for the same experiment involving three plant varieties, “A,” “B” and “C.”</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ch3-field-block"></span>
<img src="chap3_field_blocked.png" alt="Diagram of a Randomized Complete Block Design that accounts for the confouding factors of a creek and forest." width="318" />
<p class="caption">
Figure 3.3: Diagram of a Randomized Complete Block Design that accounts for the confouding factors of a creek and forest.
</p>
</div>
<p>A good experimental design will be able to “parse out” the variability due to potential confounding factors, and thus give clarity to our assessment of the factor of interest.
A block design can accomplish this task.</p>
<p><strong>What can serve as a block?</strong> It is important to note that subjects (<em>i.e.</em>, experimental units) themselves may form blocks in a block design. It is also possible that different experimental units may collectively form a “block.” It depends on the circumstances. All that is needed is that a block, however, formed, creates a “relatively homogeneous set of experimental material.”</p>
<p><strong>An example.</strong> You’ve already seen the concept of a block design! Consider the paired *<span class="math inline">\(t\)</span>-test included in Section <a href="introduction-to-statistical-modeling-and-designed-experiments.html#paired-t-test">2.4</a>. There, the individual vehicles are essentially treated as blocks.
We observe two responses within each block (or vehicle).</p>
<div id="data-structure-model-form-and-analysis-of-variance-of-a-randomized-block-design" class="section level3" number="3.1.1">
<h3><span class="header-section-number">3.1.1</span> Data structure, model form and analysis of variance of a Randomized Block Design</h3>
<p>Here is the data structure for a randomized block design (RBD) with one treatment replicate per block:</p>
<p><span class="math display">\[\begin{array}{c|cccc}
\hline
         &amp; \textbf{Treatment 1} &amp; \textbf{Treatment 2} &amp; \ldots &amp; \textbf{Treatment } k \\
\hline
\textbf{Block 1} &amp; Y_{11} &amp; Y_{21} &amp; \ldots &amp; Y_{k1} \\
\textbf{Block 2} &amp; Y_{12} &amp; Y_{22} &amp; \ldots &amp; Y_{k2} \\
\vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots \\
\textbf{Block } b &amp; Y_{1b} &amp; Y_{2b} &amp; \ldots &amp; Y_{kb} \\
\hline
\end{array}\]</span></p>
<p>The model for such data has the form</p>
<p><span class="math display">\[Y_{ij} = \mu + \tau_i + \beta_j + \varepsilon_{ij}\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(Y_{ij}\)</span> is the observation for treatment <span class="math inline">\(i\)</span> within block <span class="math inline">\(j\)</span>.</li>
<li><span class="math inline">\(\mu\)</span> is the overall mean.</li>
<li><span class="math inline">\(\tau_i\)</span> is the effect of the <span class="math inline">\(i^\mathrm{th}\)</span> treatment on the mean response.</li>
<li><span class="math inline">\(\beta_j\)</span> is the effect of the <span class="math inline">\(j^\mathrm{th}\)</span> block on the mean response.</li>
<li><span class="math inline">\(\varepsilon_{ij}\)</span> is the random error term.</li>
</ul>
<p>The usual test of interest is the same as in a one-way analysis of variance: to compare the population means due to the different treatments.
The null and alternative hypotheses are given by:
<span class="math display">\[H_0: \tau_1 = \tau_2 = \ldots = \tau_k = 0 ~~\textrm{versus}~~ H_a: \textrm{at least one } \tau_i \neq 0\]</span>
We may also test for differences between blocks, but this is usually of secondary interest at best.</p>
</div>
<div id="block-anova-example" class="section level3" number="3.1.2">
<h3><span class="header-section-number">3.1.2</span> Block ANOVA Example</h3>
<p>As a first example consider the following <em>classic</em> barley yield experiment.</p>
<p><strong>Example.</strong> Barley Yields (from <span class="citation"><a href="#ref-Fisher1935" role="doc-biblioref">Fisher</a> (<a href="#ref-Fisher1935" role="doc-biblioref">1935</a>)</span>).</p>
<p>Data was collected on the yields of five varieties of barley grown at six different locations in 1931 and 1932.
Of statistical interested is the mean difference in yield between the five different varieties.</p>
<p>Original Source: <span class="citation"><a href="#ref-ImmerHayesPowers1934" role="doc-biblioref">Immer et al.</a> (<a href="#ref-ImmerHayesPowers1934" role="doc-biblioref">1934</a>)</span></p>
<p>Before proceeding with the data analysis, we first note the variables and factors of interests in this study.</p>
<ul>
<li>Barley yield - this is the response variable.</li>
<li>Barley variety - the variety, or species, of barley. This is the factor variable of interest. It has 5 levels.</li>
<li>Location and Year - The six different location and years serve as a block term in this model. We note that within each location and year, the environment should be fairly homogenous, so the location and year will serve as a blocking term.</li>
</ul>
<p>The data is available in the file <code>fisherBarley.RData</code> on the class repository.</p>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb108-1"><a href="multiple-factor-designed-experiments.html#cb108-1" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="fu">url</span>(<span class="st">&quot;https://tjfisher19.github.io/introStatModeling/data/fisherBarley.RData&quot;</span>))</span>
<span id="cb108-2"><a href="multiple-factor-designed-experiments.html#cb108-2" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(fisherBarleyData)</span></code></pre></div>
<pre><code>## Rows: 60
## Columns: 5
## $ Yield        &lt;dbl&gt; 81.0, 80.7, 146.6, 100.4, 82.3, 103.1, 119.8, 98.9, 98.9,~
## $ Variety      &lt;chr&gt; &quot;Manchuria&quot;, &quot;Manchuria&quot;, &quot;Manchuria&quot;, &quot;Manchuria&quot;, &quot;Manc~
## $ LocationYear &lt;chr&gt; &quot;L1-31&quot;, &quot;L1-32&quot;, &quot;L2-31&quot;, &quot;L2-32&quot;, &quot;L3-31&quot;, &quot;L3-32&quot;, &quot;L4~
## $ Location     &lt;chr&gt; &quot;University Farm&quot;, &quot;University Farm&quot;, &quot;Waseca&quot;, &quot;Waseca&quot;,~
## $ Year         &lt;dbl&gt; 1931, 1932, 1931, 1932, 1931, 1932, 1931, 1932, 1931, 193~</code></pre>
<p>We note the data includes a <code>LocationYear</code> variable that combines the information of both the <code>Location</code> and <code>Year</code>.
We also note we have a single observation for each <code>Variety</code> and <code>LocationYear</code> – this we have a complete randomized block design with a single observation in each.</p>
<p>We first proceed with an inappropriate simple visualization of the data.
We do this for demonstration and learning purposes.</p>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb110-1"><a href="multiple-factor-designed-experiments.html#cb110-1" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(fisherBarleyData) <span class="sc">+</span> </span>
<span id="cb110-2"><a href="multiple-factor-designed-experiments.html#cb110-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>LocationYear, <span class="at">y=</span>Yield) ) <span class="sc">+</span></span>
<span id="cb110-3"><a href="multiple-factor-designed-experiments.html#cb110-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x=</span><span class="st">&quot;Location &amp; Year&quot;</span>, <span class="at">y=</span><span class="st">&quot;Yield (bushels)&quot;</span>)</span>
<span id="cb110-4"><a href="multiple-factor-designed-experiments.html#cb110-4" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(fisherBarleyData) <span class="sc">+</span> </span>
<span id="cb110-5"><a href="multiple-factor-designed-experiments.html#cb110-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>Variety, <span class="at">y=</span>Yield)) <span class="sc">+</span></span>
<span id="cb110-6"><a href="multiple-factor-designed-experiments.html#cb110-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x=</span><span class="st">&quot;Barley Variety&quot;</span>, <span class="at">y=</span><span class="st">&quot;Yield (bushels)&quot;</span>)</span>
<span id="cb110-7"><a href="multiple-factor-designed-experiments.html#cb110-7" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(p1, p2, <span class="at">nrow=</span><span class="dv">1</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ch3-3"></span>
<img src="introStatModeling_files/figure-html/ch3-3-1.png" alt="Boxplot distribution of the baryley yeilds of `LocationYear` and barley `Variety`." width="100%" />
<p class="caption">
Figure 3.4: Boxplot distribution of the baryley yeilds of <code>LocationYear</code> and barley <code>Variety</code>.
</p>
</div>
<p>First, a quick note about the above code.
We build a simple boxplot of the yield by the block term and call it <code>p1</code>.
Similarly we build a boxplot of yield by variety, called <code>p2</code>.
We then use the <code>grid.arrange()</code> function in the <code>gridExtra</code> package <span class="citation">(<a href="#ref-R-gridExtra" role="doc-biblioref">Auguie, 2017</a>)</span> to put the two plots side-by-side.
The results are in Figure <a href="multiple-factor-designed-experiments.html#fig:ch3-3">3.4</a>.</p>
<p><strong>Incorrect plots.</strong> We note that these plots are not necessarily appropriate for this data.
For one, Boxplots display a 5 number summary – for each block term we only have five observations (one for each variety), so the figure on the left appears to summarize a sample of data when in fact we only have 5 observations – why not just display the raw data?
Second, the figure on the right is ignoring the block structure – this is effectively equivalent to ignoring the <em>pairing</em> in a matched pairs design.
Each environmental condition consisting of a location &amp; year will have its own climate, rainfall, soil nutrients, etc…
For example, it is possible a particular barley may grow well in one Location and year due to <em>optimal</em> preciptation and sunshine levels, but another variety may grow poorly there.
Likewise, a different variety may prefer a different climate – this information cannot be deduced from this plot.</p>
<p><strong>A better plot</strong> to consider is a profile plot similar to that used in the matched pairs design in Figure <a href="introduction-to-statistical-modeling-and-designed-experiments.html#fig:ch2-7">2.2</a> from Section <a href="introduction-to-statistical-modeling-and-designed-experiments.html#paired-t-test">2.4</a>.
Here, we explore the response at each treatment level within each block term.</p>
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb111-1"><a href="multiple-factor-designed-experiments.html#cb111-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(fisherBarleyData) <span class="sc">+</span> </span>
<span id="cb111-2"><a href="multiple-factor-designed-experiments.html#cb111-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x=</span>Variety, <span class="at">y=</span>Yield, </span>
<span id="cb111-3"><a href="multiple-factor-designed-experiments.html#cb111-3" aria-hidden="true" tabindex="-1"></a>                <span class="at">color=</span>LocationYear, <span class="at">group=</span>LocationYear) ) <span class="sc">+</span></span>
<span id="cb111-4"><a href="multiple-factor-designed-experiments.html#cb111-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x=</span><span class="st">&quot;Baryley Variety&quot;</span>, <span class="at">y=</span><span class="st">&quot;Yield (bushels)&quot;</span>, <span class="at">color=</span><span class="st">&quot;Location &amp; Year&quot;</span>) <span class="sc">+</span> </span>
<span id="cb111-5"><a href="multiple-factor-designed-experiments.html#cb111-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ch3-3profile"></span>
<img src="introStatModeling_files/figure-html/ch3-3profile-1.png" alt="Profiles of each barley yield by variety profiling across each of the 12 Location &amp; Year combinations." width="70%" />
<p class="caption">
Figure 3.5: Profiles of each barley yield by variety profiling across each of the 12 Location &amp; Year combinations.
</p>
</div>
<p>This plot in Figure @(fig:ch3-3profile) is an improvement over the previous result but can be further tweaked for visual improvement.
In particular, each line corresponds to one of the block terms (this is the common approach for these plots) but there are 12 different colors displayed, and it can be difficult to distinguish them.
This can be considered <em>visual clutter</em>.
Since the specific Location &amp; Year combinations are not necessarily of interest in our study, we can <em>mute</em> their impact by plotting each line with the same color as in Figure <a href="multiple-factor-designed-experiments.html#fig:ch3-ImprovedProfile">3.6</a>.</p>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb112-1"><a href="multiple-factor-designed-experiments.html#cb112-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(fisherBarleyData) <span class="sc">+</span> </span>
<span id="cb112-2"><a href="multiple-factor-designed-experiments.html#cb112-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x=</span>Variety, <span class="at">y=</span>Yield, </span>
<span id="cb112-3"><a href="multiple-factor-designed-experiments.html#cb112-3" aria-hidden="true" tabindex="-1"></a>                <span class="at">group=</span>LocationYear), <span class="at">color=</span><span class="st">&quot;gray30&quot;</span> ) <span class="sc">+</span></span>
<span id="cb112-4"><a href="multiple-factor-designed-experiments.html#cb112-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x=</span><span class="st">&quot;Baryley Variety&quot;</span>, <span class="at">y=</span><span class="st">&quot;Yield (bushels)&quot;</span>) <span class="sc">+</span> </span>
<span id="cb112-5"><a href="multiple-factor-designed-experiments.html#cb112-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ch3-ImprovedProfile"></span>
<img src="introStatModeling_files/figure-html/ch3-ImprovedProfile-1.png" alt="Profiles of each barley yield by variety profiling across each of the 12 Location &amp; Year combinations." width="70%" />
<p class="caption">
Figure 3.6: Profiles of each barley yield by variety profiling across each of the 12 Location &amp; Year combinations.
</p>
</div>
<p>From the profile plots in Figures @(fig:ch3-3profile) and <a href="multiple-factor-designed-experiments.html#fig:ch3-ImprovedProfile">3.6</a> it is clear that certain Location &amp; Years were more fruitful than others, in terms of barley yield.
However, this is not the research question of interest - we are interested in determine how the different varieties influence yield.
From the plots, this is not as clear.
There is some evidence that the Trebi variety may result in more yield across all the blocks as well as maybe the Peatland variety.</p>
<p>To determine the effect variety has on yield we proceed with a formal analysis.
Below is a formal analysis in a call of <code>aov()</code> – making sure to check underlying assumptions in Figure <a href="multiple-factor-designed-experiments.html#fig:ch3-4">3.7</a>.</p>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb113-1"><a href="multiple-factor-designed-experiments.html#cb113-1" aria-hidden="true" tabindex="-1"></a>barley.fit <span class="ot">&lt;-</span> <span class="fu">aov</span>(Yield <span class="sc">~</span> LocationYear <span class="sc">+</span> Variety, <span class="at">data=</span>fisherBarleyData)</span>
<span id="cb113-2"><a href="multiple-factor-designed-experiments.html#cb113-2" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(barley.fit)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ch3-4"></span>
<img src="introStatModeling_files/figure-html/ch3-4-1.png" alt="Residual diagnostic plots when the response variable is the barley yield as  a function of location &amp; year (block) and variety. Here, the residuals appear fairly homoskedastic based on the Residuals vs Fitted and Scale-Location plots. The normality assumption is satisfied based on the Normal Q-Q plot." width="80%" />
<p class="caption">
Figure 3.7: Residual diagnostic plots when the response variable is the barley yield as a function of location &amp; year (block) and variety. Here, the residuals appear fairly homoskedastic based on the Residuals vs Fitted and Scale-Location plots. The normality assumption is satisfied based on the Normal Q-Q plot.
</p>
</div>
<p>The assumptions look generally fine here (nothing too concerning about constant variance or normality).
So, on to the analysis:</p>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb114-1"><a href="multiple-factor-designed-experiments.html#cb114-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(barley.fit)</span></code></pre></div>
<pre><code>##              Df Sum Sq Mean Sq F value  Pr(&gt;F)    
## LocationYear 11  31913    2901   17.00 2.1e-12 ***
## Variety       4   5310    1327    7.78 7.9e-05 ***
## Residuals    44   7509     171                    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>We see that there is a significant difference in the yield between the five varieties (<span class="math inline">\(F\)</span> = 7.779, <span class="math inline">\(\textrm{df}_1\)</span> = 4, <span class="math inline">\(\textrm{df}_2\)</span> = 44, <span class="math inline">\(p\)</span>-value = 0.0000785)</p>
<p>You can also see how the total variation was partitioned into three components:</p>
<ol style="list-style-type: decimal">
<li>Within-LocationYear (<em>i.e.</em>, the block term) sum of squares (31913).</li>
<li>Between variety (<em>i.e.</em>, treatment) sum of squares (5310).</li>
<li>Residual sum of squares (7509).</li>
</ol>
<p>We see that R also reports an <span class="math inline">\(F\)</span>-statistic and associated <span class="math inline">\(p\)</span>-value for the <code>LocationYear</code>.
This is the block term and is not of concern to our analysis.
So we <strong>ignore</strong> that <span class="math inline">\(F\)</span>-statistic and <span class="math inline">\(p\)</span>-value!</p>
<p>We can investigate the differences in yields between the five varieties using a multiple comparison procedure.</p>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb116-1"><a href="multiple-factor-designed-experiments.html#cb116-1" aria-hidden="true" tabindex="-1"></a>barley.mc <span class="ot">&lt;-</span> <span class="fu">emmeans</span>(barley.fit, <span class="st">&quot;Variety&quot;</span>)</span>
<span id="cb116-2"><a href="multiple-factor-designed-experiments.html#cb116-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">contrast</span>(barley.mc, <span class="st">&quot;pairwise&quot;</span>) )</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ch3-5a"></span>
<img src="introStatModeling_files/figure-html/ch3-5a-1.png" alt="Tukey adjusted confidence interval plots comparing the give barley varieties (treatments). Here, we see that Trebi variety is statistically different than the other four varieties, while those four are all statistically similar (recall, we look for zero in the confidence interval of the differences)." width="70%" />
<p class="caption">
Figure 3.8: Tukey adjusted confidence interval plots comparing the give barley varieties (treatments). Here, we see that Trebi variety is statistically different than the other four varieties, while those four are all statistically similar (recall, we look for zero in the confidence interval of the differences).
</p>
</div>
<p>We see that six of the ten Confidence Intervals in Figure <a href="multiple-factor-designed-experiments.html#fig:ch3-5a">3.8</a> contain the value zero, thus concluding there is not statistical difference between these varieties of barley.
However, in four of the intervals zero is not included, and all four involve the ‘Trebi’ variety of barley - this we have statistical evidence to conclude that the Trebi variety results in a different yield than the other four varieties.
Furthermore, based on the values of this intervals, it suggest that the Trebi variety will result in a greater yield than the other varieties (Trebi <span class="math inline">\(-\)</span> Variety <span class="math inline">\(&gt;0\)</span> implies Trebi <span class="math inline">\(&gt;\)</span> Variety, and Variety <span class="math inline">\(-\)</span> Trebi <span class="math inline">\(&lt;0\)</span> implies Trebi <span class="math inline">\(&gt;\)</span> Variety).</p>
</div>
<div id="another-block-anova-example" class="section level3" number="3.1.3">
<h3><span class="header-section-number">3.1.3</span> Another Block ANOVA Example</h3>
<p>The previous Block designed had roots in agriculture, much like our original description.
Here is a different example of block terms in an design.</p>
<p><strong>Example.</strong> Weight loss study (published in <span class="citation"><a href="#ref-Walpole2007" role="doc-biblioref">Walpole et al.</a> (<a href="#ref-Walpole2007" role="doc-biblioref">2007</a>)</span>).</p>
<p>Two reduction treatments and a control treatment were studied for their effects on weight change in obses women.
The two reduction treatments involved were a self-induced weight reduction program and a therapist-controlled reduction program.
Each of 10 subjects were assigned to the three treatment programs in a random order and measured for weight loss.</p>
<p>Original Source: <span class="citation"><a href="#ref-Hall1975" role="doc-biblioref">Hall</a> (<a href="#ref-Hall1975" role="doc-biblioref">1972</a>)</span></p>
<table>
<thead>
<tr>
<th style="text-align:right;">
Subject
</th>
<th style="text-align:right;">
Control
</th>
<th style="text-align:right;">
Self-induced
</th>
<th style="text-align:right;">
Therapist
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
-2.25
</td>
<td style="text-align:right;">
-10.50
</td>
</tr>
<tr>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
3.75
</td>
<td style="text-align:right;">
-6.00
</td>
<td style="text-align:right;">
-13.50
</td>
</tr>
<tr>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
-2.00
</td>
<td style="text-align:right;">
0.75
</td>
</tr>
<tr>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
-0.25
</td>
<td style="text-align:right;">
-1.50
</td>
<td style="text-align:right;">
-4.50
</td>
</tr>
<tr>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
-2.25
</td>
<td style="text-align:right;">
-3.25
</td>
<td style="text-align:right;">
-6.00
</td>
</tr>
<tr>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
-1.00
</td>
<td style="text-align:right;">
-1.50
</td>
<td style="text-align:right;">
4.00
</td>
</tr>
<tr>
<td style="text-align:right;">
7
</td>
<td style="text-align:right;">
-1.00
</td>
<td style="text-align:right;">
-10.75
</td>
<td style="text-align:right;">
-12.25
</td>
</tr>
<tr>
<td style="text-align:right;">
8
</td>
<td style="text-align:right;">
3.75
</td>
<td style="text-align:right;">
-0.75
</td>
<td style="text-align:right;">
-2.75
</td>
</tr>
<tr>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
1.50
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
-6.75
</td>
</tr>
<tr>
<td style="text-align:right;">
10
</td>
<td style="text-align:right;">
0.50
</td>
<td style="text-align:right;">
-3.75
</td>
<td style="text-align:right;">
-7.00
</td>
</tr>
</tbody>
</table>
<p>There data are available in the R dataframe <code>wordrecall.RData</code> on the class repository (<code>https://tjfisher19.github.io/introStatModeling/data/</code>). Below is an analysis of this data.</p>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb117-1"><a href="multiple-factor-designed-experiments.html#cb117-1" aria-hidden="true" tabindex="-1"></a>weightloss <span class="ot">&lt;-</span> <span class="fu">read_tsv</span>(<span class="st">&quot;https://tjfisher19.github.io/introStatModeling/data/weightlossStudy.csv&quot;</span>)</span>
<span id="cb117-2"><a href="multiple-factor-designed-experiments.html#cb117-2" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(weightloss)</span></code></pre></div>
<pre><code>## Rows: 30
## Columns: 3
## $ Subject   &lt;dbl&gt; 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7, 7, ~
## $ Treatment &lt;chr&gt; &quot;Control&quot;, &quot;Self-induced&quot;, &quot;Therapist&quot;, &quot;Control&quot;, &quot;Self-ind~
## $ WtChanges &lt;dbl&gt; 1.00, -2.25, -10.50, 3.75, -6.00, -13.50, 0.00, -2.00, 0.75,~</code></pre>
<p>Each subject gives three responses instead of one as in a usual one-way design.
In this manner, each subject (or person) forms a block (a person is a fairly homogeneous).
The design is a randomized block design, because the experimenter randomly determines the order of treatments for each subject.</p>
<p>Before the formal analysis we build profile plots to explore the effects of the three treatments within each subject in Figure <a href="multiple-factor-designed-experiments.html#fig:ch3-WeightPprofiles">3.9</a>.</p>
<div class="sourceCode" id="cb119"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb119-1"><a href="multiple-factor-designed-experiments.html#cb119-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(weightloss, <span class="fu">aes</span>(<span class="at">x=</span>Treatment, <span class="at">y=</span>WtChanges)) <span class="sc">+</span> </span>
<span id="cb119-2"><a href="multiple-factor-designed-experiments.html#cb119-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">group=</span>Subject), <span class="at">color=</span><span class="st">&quot;gray30&quot;</span> ) <span class="sc">+</span></span>
<span id="cb119-3"><a href="multiple-factor-designed-experiments.html#cb119-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_summary</span>(<span class="at">fun=</span><span class="st">&quot;mean&quot;</span>, <span class="at">geom=</span><span class="st">&quot;line&quot;</span>, <span class="at">size=</span><span class="dv">2</span>, <span class="at">group=</span><span class="dv">1</span>, <span class="at">color=</span><span class="st">&quot;blue&quot;</span>) <span class="sc">+</span> </span>
<span id="cb119-4"><a href="multiple-factor-designed-experiments.html#cb119-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x=</span><span class="st">&quot;Weight Loss Treatment&quot;</span>, <span class="at">y=</span><span class="st">&quot;Weight Change&quot;</span>) <span class="sc">+</span> </span>
<span id="cb119-5"><a href="multiple-factor-designed-experiments.html#cb119-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ch3-WeightPprofiles"></span>
<img src="introStatModeling_files/figure-html/ch3-WeightPprofiles-1.png" alt="Profiles of each subject's weight loss for the different treatments, with an overlayed 'average' highlighted in blue." width="70%" />
<p class="caption">
Figure 3.9: Profiles of each subject’s weight loss for the different treatments, with an overlayed ‘average’ highlighted in blue.
</p>
</div>
<p>Overall, in Figure <a href="multiple-factor-designed-experiments.html#fig:ch3-WeightPprofiles">3.9</a> the effect of the different treatments appears quite stark, with the Therapist and Self-induced treatments improving over the control.
There is also quite a bit of subject-to-subject variability (<em>i.e.</em>, each person has their own profile!) and some subjects do not follow the “average” profile.</p>
<p>Here is how to do a formal analysis in a call of <code>aov()</code> – making sure to check underlying assumptions in Figure <a href="multiple-factor-designed-experiments.html#fig:ch3-weightlossANOVA">3.10</a>.</p>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb120-1"><a href="multiple-factor-designed-experiments.html#cb120-1" aria-hidden="true" tabindex="-1"></a>weightloss.fit <span class="ot">&lt;-</span> <span class="fu">aov</span>(WtChanges <span class="sc">~</span> Subject <span class="sc">+</span> Treatment, <span class="at">data=</span>weightloss)</span>
<span id="cb120-2"><a href="multiple-factor-designed-experiments.html#cb120-2" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(weightloss.fit)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ch3-weightlossANOVA"></span>
<img src="introStatModeling_files/figure-html/ch3-weightlossANOVA-1.png" alt="Residual diagnostic plots when the response variable is the weight change as a function of subject (block) and treatment. Here, the residuals appear to show some minor violations to the constant variance assumption as indicated by the Residuals vs Fitted and Scale-Location plots. Except for a single concerning observation, the normality assumption is satisfied based on the Normal Q-Q plot." width="80%" />
<p class="caption">
Figure 3.10: Residual diagnostic plots when the response variable is the weight change as a function of subject (block) and treatment. Here, the residuals appear to show some minor violations to the constant variance assumption as indicated by the Residuals vs Fitted and Scale-Location plots. Except for a single concerning observation, the normality assumption is satisfied based on the Normal Q-Q plot.
</p>
</div>
<p>There appears to be a minor violation in the constant variance assumption (there is some indication that fitted values away from zero are more variable?).
But, this type of violation cannot be easily be remedied by the standard techniques (a logarithm or square root transformation is not possible due to the negative values, and an reciprocal transformation is not possible due to a 0 observation).
A single observation (observation 16) has a largest <span class="math inline">\(z\)</span>-score value which deviates from the Normal line.
We proceed with the analysis making note of some potential minor assumption violations.</p>
<div class="sourceCode" id="cb121"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb121-1"><a href="multiple-factor-designed-experiments.html#cb121-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(weightloss.fit)</span></code></pre></div>
<pre><code>##             Df Sum Sq Mean Sq F value Pr(&gt;F)   
## Subject      1      3     3.0    0.19  0.663   
## Treatment    2    210   105.0    6.88  0.004 **
## Residuals   26    397    15.3                  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>We see that there is a significant difference in the mean weight change between the three treatments (<span class="math inline">\(F\)</span> = 6.878, <span class="math inline">\(\textrm{df}_1\)</span> = 2, <span class="math inline">\(\textrm{df}_2\)</span> = 26, <span class="math inline">\(p\)</span>-value = 0.004).</p>
<p>As a follow-up, we can investigate the differences in mean weight changes between the three treatments using a multiple comparison procedure and noting that there is a control treatment.</p>
<div class="sourceCode" id="cb123"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb123-1"><a href="multiple-factor-designed-experiments.html#cb123-1" aria-hidden="true" tabindex="-1"></a>weightloss.mc <span class="ot">&lt;-</span> <span class="fu">emmeans</span>(weightloss.fit, <span class="st">&quot;Treatment&quot;</span>)</span>
<span id="cb123-2"><a href="multiple-factor-designed-experiments.html#cb123-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">contrast</span>(weightloss.mc, <span class="st">&quot;trt.vs.ctrl&quot;</span>) )</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ch3-WeightMC"></span>
<img src="introStatModeling_files/figure-html/ch3-WeightMC-1.png" alt="Dunnett adjusted confidence interval plots comparing the two weight-loss treatments against the control. Here, we see that Self-induced treatment is not statistically different than the control (zero is in the interval) while the Therapist based treatment results in significantly more weight loss than the control." width="70%" />
<p class="caption">
Figure 3.11: Dunnett adjusted confidence interval plots comparing the two weight-loss treatments against the control. Here, we see that Self-induced treatment is not statistically different than the control (zero is in the interval) while the Therapist based treatment results in significantly more weight loss than the control.
</p>
</div>
<p>The confidence intervals comparing the therapist-based weight loss treatment to the control in Figure <a href="multiple-factor-designed-experiments.html#fig:ch3-WeightMC">3.11</a> does not contain the value zero, so we have evidence to suggest that the therapist based method results in a bigger weight change.
However, the interval comparing the self-induced method to the control indicates there is not statistical difference (zero is included in the interval).</p>
</div>
</div>
<div id="two-factor-designs" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Two-factor Designs</h2>
<p>A <strong>factorial</strong> structure in an experimental design is one in which there are two or more factors, and the levels of the factors are all observed in combination.
For example, suppose you are testing for the effectiveness of three drugs (A, B, C) at three different dosages (5 mg, 10 mg, 25 mg).
In a factorial design, you would observed a total of nine treatments, each of which consists of a combination of drug and dose (<em>e.g.</em>, treatment 1 is drug A administered at 5 mg, treatment 2 is drug A administered at 10 mg, etc).
Note how quickly things will grow if you have more than two factors!</p>
<p>In this design, the data are usually obtained by collecting a random sample of individuals to participate in the study, and then randomly allocating a single treatment to each of the study participants as in a one-way design structure.
The only difference now is that a “treatment” consists of a combination of different factors.
If there are two factors, the data may be analyzed using a two-way ANOVA.</p>
<p>The two-way data structure with two factors <span class="math inline">\(\mathbf{A}\)</span> and <span class="math inline">\(\mathbf{B}\)</span> looks like the following:</p>
<p><span class="math display">\[\begin{array}{c|cccc}
\hline
 &amp; \mathbf{A_1} &amp; \mathbf{A_2} &amp; \mathbf{\ldots} &amp; \mathbf{A_a} \\
\hline
\mathbf{B_1} &amp; Y_{111}, Y_{112}, \ldots &amp; Y_{211}, Y_{212}, \ldots, &amp; \ldots &amp; Y_{a11}, Y_{a12}, \ldots \\
\mathbf{B_2} &amp; Y_{121}, Y_{122}, \ldots &amp; Y_{221}, Y_{222}, \ldots, &amp; \ldots &amp; Y_{a21}, Y_{a22}, \ldots \\
\mathbf{B_3} &amp; Y_{131}, Y_{132}, \ldots &amp; Y_{231}, Y_{232}, \ldots, &amp; \ldots &amp; Y_{a31}, Y_{a32}, \ldots \\
\vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots \\
\mathbf{B_b} &amp; Y_{1b1}, Y_{1b2}, \ldots &amp; Y_{2b1}, Y_{2b2}, \ldots, &amp; \ldots &amp; Y_{ab1}, Y_{ab2}, \ldots \\
\hline
\end{array}\]</span></p>
<p>Note there is replication (<em>i.e.</em>, multiple independent observations) in each treatment (combination of factors <span class="math inline">\(\mathbf{A}\)</span> and <span class="math inline">\(\mathbf{B}\)</span>).</p>
<p>The general model for such data has the form</p>
<p><span class="math display">\[Y_{ijk} = \mu + \alpha_i + \beta_j + \alpha\beta_{ij} + \varepsilon_{ijk}\]</span>
where</p>
<ul>
<li><span class="math inline">\(Y_{ijk}\)</span> is the <span class="math inline">\(k^\mathrm{th}\)</span> observation in the <span class="math inline">\(i^\mathrm{th}\)</span> level of factor <span class="math inline">\(A\)</span> and the <span class="math inline">\(j^\mathrm{th}\)</span> level of factor <span class="math inline">\(B\)</span>.</li>
<li><span class="math inline">\(\mu\)</span> is the overall mean.</li>
<li><span class="math inline">\(\alpha_i\)</span> is the “main effect” of the <span class="math inline">\(i^\mathrm{th}\)</span> level of factor <span class="math inline">\(A\)</span> on the mean response.</li>
<li><span class="math inline">\(\beta_j\)</span> is the “main effect” of the <span class="math inline">\(j^\mathrm{th}\)</span> level of factor <span class="math inline">\(B\)</span> on the mean response.</li>
<li><span class="math inline">\(\alpha\beta_{ij}\)</span> is the “interaction effect” of the <span class="math inline">\(i^\mathrm{th}\)</span> level of factor <span class="math inline">\(A\)</span> and the <span class="math inline">\(j^\mathrm{th}\)</span> level of factor <span class="math inline">\(B\)</span> on the mean response.</li>
<li><span class="math inline">\(\varepsilon_{ijk}\)</span> is the random error term.</li>
</ul>
<div id="analysis-of-a-two-factor-design" class="section level3" number="3.2.1">
<h3><span class="header-section-number">3.2.1</span> Analysis of a two-factor design</h3>
<p>First recall an important feature of designed experiments – the analysis is determined by the experiment!
In most cases of factorial designs, the primary interest is to determine if some interaction between the two factors influences the response.
Therefore it is crucial to test the interaction term before assessing the effects of factor <span class="math inline">\(A\)</span> alone on the response, because if <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> interact, then we cannot separate their effects.
In other words, if the interaction between <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> significantly influences the response, then the effect that factor <span class="math inline">\(A\)</span> has on the response changes depending on the level of factor <span class="math inline">\(B\)</span>.</p>
<p>The usual testing strategy is as follows:</p>
<ol style="list-style-type: decimal">
<li>Fit a full interaction model.</li>
<li>Test for significant interaction between <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>:
<ol style="list-style-type: lower-alpha">
<li>If the interaction term is significant, you must look at comparisons in terms of treatment combination; <em>i.e.</em>, you cannot separate the effects of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>.</li>
<li>If the interaction term is non-significant, you can look into deleting the interaction term from your model, fitting a reduced <strong>main-effects model</strong>. Then (and only then) may you look at the effects of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> separately.</li>
</ol></li>
</ol>
<p>We consider two examples below.</p>
</div>
<div id="example-with-no-interaction" class="section level3" number="3.2.2">
<h3><span class="header-section-number">3.2.2</span> Example with No Interaction</h3>
<p><strong>Example.</strong> Highway Signage (published in <span class="citation"><a href="#ref-WeissText" role="doc-biblioref">Weiss</a> (<a href="#ref-WeissText" role="doc-biblioref">2012</a>)</span>).</p>
<p>An experiment was conducted to determine the effects that the sign size and sign material have on <em>detection distance</em> (the distance at which drivers can first detect highway caution signs).
Four drivers were randomly selected for each combination of sign size (small, medium, and large) and sign material (marked 1, 2, and 3).
Each driver covered the same streth of highway at a constant speed during the same time of day, and the detection distance (in feet) was determined for hte driver’s assignment caution sign.</p>
<p>Original Source: <span class="citation"><a href="#ref-Younes1994" role="doc-biblioref">Younes</a> (<a href="#ref-Younes1994" role="doc-biblioref">1194</a>)</span></p>
<p>The data appear in the csv file <code>highwaySigns.tsv</code> in the textbook repository.</p>
<p>First note the data is stormed in a “Tab separated values” file, or TSV.
This is similar to the more common, “Comma Separated values,” or CSV, format.
The <code>readr</code> package includes a <code>read_tsv()</code> function that works just like <code>read_csv()</code> and <code>read_table()</code>.</p>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb124-1"><a href="multiple-factor-designed-experiments.html#cb124-1" aria-hidden="true" tabindex="-1"></a>highway_signs <span class="ot">&lt;-</span> <span class="fu">read_tsv</span>(<span class="st">&quot;https://tjfisher19.github.io/introStatModeling/data/highwaySigns.tsv&quot;</span>, <span class="at">col_types=</span><span class="fu">cols</span>())</span>
<span id="cb124-2"><a href="multiple-factor-designed-experiments.html#cb124-2" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(highway_signs)</span></code></pre></div>
<pre><code>## Rows: 36
## Columns: 3
## $ Distance &lt;dbl&gt; 2503, 1929, 1512, 2774, 2187, 2288, 3354, 2920, 2928, 2427, 2~
## $ Size     &lt;chr&gt; &quot;Small&quot;, &quot;Small&quot;, &quot;Small&quot;, &quot;Medium&quot;, &quot;Medium&quot;, &quot;Medium&quot;, &quot;Lar~
## $ Material &lt;dbl&gt; 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3~</code></pre>
<p>Take a look at the detection distances by treatment and note that we need to coerce the <code>Material</code> variable to be a factor variable since it is coded as a numer.
We will also turn `Size1 into a factor with a more logical order (recall that R will put the values in alphabetical order by default).</p>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb126-1"><a href="multiple-factor-designed-experiments.html#cb126-1" aria-hidden="true" tabindex="-1"></a>highway_signs <span class="ot">&lt;-</span> highway_signs <span class="sc">%&gt;%</span></span>
<span id="cb126-2"><a href="multiple-factor-designed-experiments.html#cb126-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Material =</span> <span class="fu">as.factor</span>(Material),</span>
<span id="cb126-3"><a href="multiple-factor-designed-experiments.html#cb126-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">Size =</span> <span class="fu">factor</span>(Size, <span class="at">levels=</span><span class="fu">c</span>(<span class="st">&quot;Small&quot;</span>, <span class="st">&quot;Medium&quot;</span>, <span class="st">&quot;Large&quot;</span>)))</span></code></pre></div>
<p>Now we wish to construct a plot of the data.
We note that we have 4 observations per treatment (combination of size and material) so a boxplot makes no sense here.
We attempt to plot the raw data, using color to distinguish the three sign materials.
We also add some <em>jittering</em> and <em>dodging</em> to separate data points and materials.</p>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb127-1"><a href="multiple-factor-designed-experiments.html#cb127-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(highway_signs) <span class="sc">+</span> </span>
<span id="cb127-2"><a href="multiple-factor-designed-experiments.html#cb127-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">x=</span>Size, <span class="at">y=</span>Distance, <span class="at">color=</span>Material),</span>
<span id="cb127-3"><a href="multiple-factor-designed-experiments.html#cb127-3" aria-hidden="true" tabindex="-1"></a>              <span class="at">position=</span><span class="fu">position_jitterdodge</span>() ) <span class="sc">+</span> </span>
<span id="cb127-4"><a href="multiple-factor-designed-experiments.html#cb127-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x=</span><span class="st">&quot;Sign Size&quot;</span>, <span class="at">y=</span><span class="st">&quot;Detection Distance (ft)&quot;</span>) <span class="sc">+</span></span>
<span id="cb127-5"><a href="multiple-factor-designed-experiments.html#cb127-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ch3-6"></span>
<img src="introStatModeling_files/figure-html/ch3-6-1.png" alt="Boxplot distribution of the texture values as a function of sauce and fish type." width="100%" />
<p class="caption">
Figure 3.12: Boxplot distribution of the texture values as a function of sauce and fish type.
</p>
</div>
<p>From Figure <a href="multiple-factor-designed-experiments.html#fig:ch3-6">3.12</a>, there appears to be a size effect: Large signs have larger detection distances, followed by medium sized and then small.
There may be a material effect as material type 3 appears to have lower detection distances than type 1.
Material type 2 is somewhere between types 1 and 3 in terms of detection distances.</p>
<p>We fit the interaction model in <code>aov()</code> by telling R to include an interaction term with the notation <code>factor1:factor2</code>.
Below is the specific example for this study but first run a check on the residuals in Figure <a href="multiple-factor-designed-experiments.html#fig:ch3-7">3.13</a>.</p>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb128-1"><a href="multiple-factor-designed-experiments.html#cb128-1" aria-hidden="true" tabindex="-1"></a>highway.fit <span class="ot">&lt;-</span> <span class="fu">aov</span>(Distance <span class="sc">~</span> Size <span class="sc">+</span> Material <span class="sc">+</span> Size<span class="sc">:</span>Material, <span class="at">data=</span>highway_signs)</span>
<span id="cb128-2"><a href="multiple-factor-designed-experiments.html#cb128-2" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(highway.fit)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ch3-7"></span>
<img src="introStatModeling_files/figure-html/ch3-7-1.png" alt="Residual diagnostic plots when the response variable is the detection distance as a function of sign size and sign material. Here, the residuals appear fairly homoskedastic based on the Residuals vs Fitted and Scale-Location plots. The normality assumption is satisfied based on the Normal Q-Q plot." width="80%" />
<p class="caption">
Figure 3.13: Residual diagnostic plots when the response variable is the detection distance as a function of sign size and sign material. Here, the residuals appear fairly homoskedastic based on the Residuals vs Fitted and Scale-Location plots. The normality assumption is satisfied based on the Normal Q-Q plot.
</p>
</div>
<p>The assumptions look to be reasonably met.
While there may be some minor issues with constant variance, it does not appear to be systemically related to the predicted (fitted) values, so transformations will not be helpful.
Likewise, those few observations in the QQ-Plot are not overly concerning given their <span class="math inline">\(z\)</span>-score values are in the range <span class="math inline">\((-2,2)\)</span>.</p>
<p>At this point, we can also generate tables of response means after we fit the interaction model.
These consist of:</p>
<ul>
<li>The “grand mean” (overall mean, all data pooled together and estimate <span class="math inline">\(\mu\)</span>).</li>
<li>Main effect means (<em>i.e.</em>, means for each factor level, taken one factor at a time).</li>
<li>Interaction means (<em>i.e.</em>, treatment means for all factor combinations).</li>
</ul>
<p>These means are estimates from the data and are purely descriptive (like the boxplots were), but informative nonetheless.
We could calculate each one of the above using a series of <code>tidyverse</code> commands or using the R function <code>model.tables()</code>:</p>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb129-1"><a href="multiple-factor-designed-experiments.html#cb129-1" aria-hidden="true" tabindex="-1"></a><span class="fu">model.tables</span>(highway.fit, <span class="st">&quot;means&quot;</span>)</span></code></pre></div>
<pre><code>## Tables of means
## Grand mean
##         
## 2552.33 
## 
##  Size 
## Size
##  Small Medium  Large 
## 2104.8 2505.9 3046.2 
## 
##  Material 
## Material
##      1      2      3 
## 2884.9 2522.9 2249.2 
## 
##  Size:Material 
##         Material
## Size     1    2    3   
##   Small  2486 2158 1670
##   Medium 2804 2381 2333
##   Large  3365 3029 2744</code></pre>
<p>We proceed to the hypothesis tests:</p>
<div class="sourceCode" id="cb131"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb131-1"><a href="multiple-factor-designed-experiments.html#cb131-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(highway.fit)</span></code></pre></div>
<pre><code>##               Df  Sum Sq Mean Sq F value  Pr(&gt;F)    
## Size           2 5356373 2678187   50.91 6.9e-10 ***
## Material       2 2440644 1220322   23.20 1.4e-06 ***
## Size:Material  4  217044   54261    1.03    0.41    
## Residuals     27 1420315   52604                    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p><strong>The first test to inspect is the interaction test.</strong> The interaction is insignificant (<span class="math inline">\(F\)</span> = 1.031, <span class="math inline">\(\textrm{df}_1\)</span> = 4, <span class="math inline">\(\textrm{df}_2\)</span> = 27, <span class="math inline">\(p\)</span>-value = 0.409). Thus, we could conclude the effect that sign size type has on the mean detection distance does not depend on material type.</p>
<p>A visualization of the interaction effect may be obtained using an interactions plot.
An interaction plot is basically a plot of treatment means, whereby the means for all treatments having a given fixed level of one of the factors are visually “connected.”
We can build the interaction plot seen in Figure <a href="multiple-factor-designed-experiments.html#fig:ch3-10">3.14</a> using aesthetic options in <code>ggplot()</code> and with the <code>stat_summary</code> functions.
Note both <code>color</code> and <code>group</code> are determined based on the <code>gender</code> variable.</p>
<div class="sourceCode" id="cb133"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb133-1"><a href="multiple-factor-designed-experiments.html#cb133-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(highway.fit, </span>
<span id="cb133-2"><a href="multiple-factor-designed-experiments.html#cb133-2" aria-hidden="true" tabindex="-1"></a>       <span class="fu">aes</span>(<span class="at">x=</span>Size, <span class="at">y=</span>Distance, <span class="at">color=</span>Material, <span class="at">group=</span>Material) ) <span class="sc">+</span>  </span>
<span id="cb133-3"><a href="multiple-factor-designed-experiments.html#cb133-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_summary</span>(<span class="at">fun=</span>mean, <span class="at">geom=</span><span class="st">&quot;point&quot;</span>) <span class="sc">+</span> </span>
<span id="cb133-4"><a href="multiple-factor-designed-experiments.html#cb133-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_summary</span>(<span class="at">fun=</span>mean, <span class="at">geom=</span><span class="st">&quot;line&quot;</span>) <span class="sc">+</span></span>
<span id="cb133-5"><a href="multiple-factor-designed-experiments.html#cb133-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x=</span><span class="st">&quot;Sign Size&quot;</span>, <span class="at">y=</span><span class="st">&quot;Mean Detection Distance (ft)&quot;</span>, <span class="at">color=</span><span class="st">&quot;Material&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ch3-10"></span>
<img src="introStatModeling_files/figure-html/ch3-10-1.png" alt="Interaction plot demonstrating that the gender and dosage factors do not interact." width="70%" />
<p class="caption">
Figure 3.14: Interaction plot demonstrating that the gender and dosage factors do not interact.
</p>
</div>
<p>There are three treatment mean traces, one for each material type.
Each trace connects the mean detection distance of the sign size within each material.</p>
<p><strong>The lack of significant interaction is evidenced by the parallelism of these traces:</strong> the material effect for small signs is depicted by the “gaps” between the traces on the left.
Similarly, the material effect for the medium signs is depicted by the gaps at the middle points.
Likewise, the material effect for the large signs is dipicted by the gaps at the right points.
Overall the three lines are reasonably parallel, and the interaction is not significant, this implies that the effect of material type within three sign sizes is about the same across all sign sizes.</p>
<p>In other words, the effect of material type does not depend on sign size.</p>
<p>The interaction term was non-significant.
Visually, we may have support that the two factors do not interact.
We can consider a reduced model that eliminates the interaction term and includes only main effects:</p>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb134-1"><a href="multiple-factor-designed-experiments.html#cb134-1" aria-hidden="true" tabindex="-1"></a>highway.main.fit <span class="ot">&lt;-</span> <span class="fu">aov</span>(Distance <span class="sc">~</span> Size <span class="sc">+</span> Material, <span class="at">data=</span>highway_signs)</span>
<span id="cb134-2"><a href="multiple-factor-designed-experiments.html#cb134-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(highway.main.fit)</span></code></pre></div>
<pre><code>##             Df  Sum Sq Mean Sq F value  Pr(&gt;F)    
## Size         2 5356373 2678187    50.7 1.7e-10 ***
## Material     2 2440644 1220322    23.1 7.2e-07 ***
## Residuals   31 1637358   52818                    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>From the results here (or with the interaction model), we see that the both material type and sign size appear to influence the detection distance of the fish (both <span class="math inline">\(p\)</span>-values are smaller than typically-used significance levels).</p>
<p>At this point, the follow-up work would involve multiple comparisons among the levels of the significant main effect factors.
Here, since ther is no interaction, we can perform multiple comparisons within each of the main effects separately.
First, we look at the influence of sign size.</p>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb136-1"><a href="multiple-factor-designed-experiments.html#cb136-1" aria-hidden="true" tabindex="-1"></a>twoway.size.mc <span class="ot">&lt;-</span> <span class="fu">emmeans</span>(highway.main.fit, <span class="st">&quot;Size&quot;</span>)</span>
<span id="cb136-2"><a href="multiple-factor-designed-experiments.html#cb136-2" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(<span class="fu">contrast</span>(twoway.size.mc, <span class="st">&quot;pairwise&quot;</span>))</span></code></pre></div>
<pre><code>##  contrast       estimate   SE df lower.CL upper.CL
##  Small - Medium     -401 93.8 31     -632     -170
##  Small - Large      -941 93.8 31    -1172     -710
##  Medium - Large     -540 93.8 31     -771     -309
## 
## Results are averaged over the levels of: Material 
## Confidence level used: 0.95 
## Conf-level adjustment: tukey method for comparing a family of 3 estimates</code></pre>
<p>We note that the adjusted 95% confidence do not include the value 0, thus all sign sizes result in different detection distances.</p>
<p>For the three different material types.</p>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb138-1"><a href="multiple-factor-designed-experiments.html#cb138-1" aria-hidden="true" tabindex="-1"></a>twoway.material.mc <span class="ot">&lt;-</span> <span class="fu">emmeans</span>(highway.main.fit, <span class="st">&quot;Material&quot;</span>)</span>
<span id="cb138-2"><a href="multiple-factor-designed-experiments.html#cb138-2" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(<span class="fu">contrast</span>(twoway.material.mc, <span class="st">&quot;pairwise&quot;</span>))</span></code></pre></div>
<pre><code>##  contrast estimate   SE df lower.CL upper.CL
##  1 - 2         362 93.8 31    131.1      593
##  1 - 3         636 93.8 31    404.8      867
##  2 - 3         274 93.8 31     42.8      505
## 
## Results are averaged over the levels of: Size 
## Confidence level used: 0.95 
## Conf-level adjustment: tukey method for comparing a family of 3 estimates</code></pre>
<p>Similar to the above, we note that all three confidence intervals do not include the value of 0, indicating that all three material types result in different mean detection distances.</p>
</div>
<div id="example-with-interaction" class="section level3" number="3.2.3">
<h3><span class="header-section-number">3.2.3</span> Example with Interaction</h3>
<p><strong>Example.</strong> Tooth growth in guinea pigs (original from <span class="citation"><a href="#ref-Crampton-1947" role="doc-biblioref">Crampton</a> (<a href="#ref-Crampton-1947" role="doc-biblioref">1947</a>)</span>).</p>
<p>Consider an example that investigates the effects of ascorbic acid and delivery method on tooth growth in guinea pigs.
Sixty guinea pigs are randomly assigned to receive one of three levels of ascorbic acid (0.5, 1.0 or 2.0 mg) via one of two delivery methods (orange juice or Vitamin C), under the restriction that each treatment combination has an equal number of guinea pigs.
The response variable <code>len</code> is the length of odontoblasts (cells responsible for tooth growth).
The two-way data structure here looks like this:</p>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="1">
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="3">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Dose
</div>
</th>
</tr>
<tr>
<th style="text-align:left;">
Supplement
</th>
<th style="text-align:left;">
0.5 mg
</th>
<th style="text-align:left;">
1.0 mg
</th>
<th style="text-align:left;">
2.0 mg
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Orange Juice
</td>
<td style="text-align:left;">
Treatment 1
</td>
<td style="text-align:left;">
Treatment 2
</td>
<td style="text-align:left;">
Treatment 3
</td>
</tr>
<tr>
<td style="text-align:left;">
Vitamin C
</td>
<td style="text-align:left;">
Treatment 4
</td>
<td style="text-align:left;">
Treatment 5
</td>
<td style="text-align:left;">
Treatment 6
</td>
</tr>
</tbody>
</table>
<p>As alluded to before, there are ten replicate guinea pigs per treatment.
The data appear in the R workspace <code>ToothGrowth</code> included in the <code>datasets</code> package <span class="citation">(<a href="#ref-R-base" role="doc-biblioref">R Core Team, 2019</a>)</span>.
Here is the head of the dataframe:</p>
<div class="sourceCode" id="cb140"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb140-1"><a href="multiple-factor-designed-experiments.html#cb140-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;ToothGrowth&quot;</span>)</span>
<span id="cb140-2"><a href="multiple-factor-designed-experiments.html#cb140-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(ToothGrowth)</span></code></pre></div>
<pre><code>##    len supp dose
## 1  4.2   VC  0.5
## 2 11.5   VC  0.5
## 3  7.3   VC  0.5
## 4  5.8   VC  0.5
## 5  6.4   VC  0.5
## 6 10.0   VC  0.5</code></pre>
<p>Let us bypass generating numeric descriptive statistics for the moment, and instead jump to an interaction plot of the length response in Figure <a href="multiple-factor-designed-experiments.html#fig:ch3-15">3.15</a>.</p>
<div class="sourceCode" id="cb142"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb142-1"><a href="multiple-factor-designed-experiments.html#cb142-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(ToothGrowth, <span class="fu">aes</span>(<span class="at">x=</span>dose, <span class="at">y=</span>len, <span class="at">group=</span>supp, <span class="at">color=</span>supp) ) <span class="sc">+</span>  </span>
<span id="cb142-2"><a href="multiple-factor-designed-experiments.html#cb142-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_summary</span>(<span class="at">fun=</span>mean, <span class="at">geom=</span><span class="st">&quot;point&quot;</span>) <span class="sc">+</span> </span>
<span id="cb142-3"><a href="multiple-factor-designed-experiments.html#cb142-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_summary</span>(<span class="at">fun=</span>mean, <span class="at">geom=</span><span class="st">&quot;line&quot;</span>) <span class="sc">+</span></span>
<span id="cb142-4"><a href="multiple-factor-designed-experiments.html#cb142-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x=</span><span class="st">&quot;Dosage (mg per day)&quot;</span>, <span class="at">y=</span><span class="st">&quot;Length of dontoblasts&quot;</span>,</span>
<span id="cb142-5"><a href="multiple-factor-designed-experiments.html#cb142-5" aria-hidden="true" tabindex="-1"></a>       <span class="at">color=</span><span class="st">&quot;Supplement&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ch3-15"></span>
<img src="introStatModeling_files/figure-html/ch3-15-1.png" alt="Interaction plot demonstrating that the dose and supplement may interact in predicting tooth length." width="70%" />
<p class="caption">
Figure 3.15: Interaction plot demonstrating that the dose and supplement may interact in predicting tooth length.
</p>
</div>
<p>There are a couple of things to note here:</p>
<ol style="list-style-type: decimal">
<li>There appears to be a substantial dose effect, in that higher doses of ascorbic acid generally result in higher mean length.</li>
<li><strong>However, there may be a substantial interaction effect between the type of supplement and dose in determining mean tooth length.</strong> In particular, orange juice appears to be more effective than Vitamin C as a delivery method (longer tooth length), but only at lower dose levels. At the high dose level, there appears to be no difference between the supplements.</li>
</ol>
<p>Once again, non-parallel traces may be the red flag.
But, we need to run the ANOVA test for interaction to confirm if this is a significant effect.
First, check assumptions in Figure <a href="multiple-factor-designed-experiments.html#fig:ch3-16">3.16</a>.</p>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb143-1"><a href="multiple-factor-designed-experiments.html#cb143-1" aria-hidden="true" tabindex="-1"></a>tooth.fit <span class="ot">&lt;-</span> <span class="fu">aov</span>(len <span class="sc">~</span> <span class="fu">factor</span>(dose) <span class="sc">+</span> supp <span class="sc">+</span> <span class="fu">factor</span>(dose)<span class="sc">:</span>supp, <span class="at">data=</span>ToothGrowth)</span>
<span id="cb143-2"><a href="multiple-factor-designed-experiments.html#cb143-2" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(tooth.fit)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ch3-16"></span>
<img src="introStatModeling_files/figure-html/ch3-16-1.png" alt="Residual diagnostic plots when the response variable is the tooth length as a function of supplement and dosage. Here, the residuals appear fairly homoskedastic based on the Residuals vs Fitted and Scale-Location plots. The normality assumption is satisfied based on the Normal Q-Q plot." width="80%" />
<p class="caption">
Figure 3.16: Residual diagnostic plots when the response variable is the tooth length as a function of supplement and dosage. Here, the residuals appear fairly homoskedastic based on the Residuals vs Fitted and Scale-Location plots. The normality assumption is satisfied based on the Normal Q-Q plot.
</p>
</div>
<p>All assumptions look fine here.
So, proceed to the ANOVA tests:</p>
<div class="sourceCode" id="cb144"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb144-1"><a href="multiple-factor-designed-experiments.html#cb144-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(tooth.fit)</span></code></pre></div>
<pre><code>##                   Df Sum Sq Mean Sq F value  Pr(&gt;F)    
## factor(dose)       2   2426    1213   92.00 &lt; 2e-16 ***
## supp               1    205     205   15.57 0.00023 ***
## factor(dose):supp  2    108      54    4.11 0.02186 *  
## Residuals         54    712      13                    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The test for interaction is significant (<span class="math inline">\(F\)</span> = 4.107, <span class="math inline">\(\textrm{df}_1\)</span> = 2, <span class="math inline">\(\textrm{df}_2\)</span> = 54, <span class="math inline">\(p\)</span>-value = 0.0218).
Thus, we conclude the effect that supplement has on the mean tooth growth does depend on the dosage level. <strong>We then ignore the main effects tests if the interaction is significant.</strong></p>
<p>Remember the strategy we introduced earlier:</p>
<ol style="list-style-type: decimal">
<li>Fit a full interaction model.</li>
<li>Test for significant interaction between <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>:
<ol style="list-style-type: lower-alpha">
<li><strong>If interaction is significant, you must look at comparisons in terms of treatment combinations; <em>i.e.</em>, you cannot separate the effects of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span></strong>.</li>
<li>If interaction is non-significant, you may delete the interaction term from the model, fitting a reduced main-effects model. Then (and only then) may you look at the effects of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> separately.</li>
</ol></li>
</ol>
<p><strong>Performing multiple comparisons. </strong>In the case of a significant interaction effect in a two-factor ANOVA model, we typically follow up by performing multiple comparisons for the levels of one of the factors while holding the other factor fixed (the “conditioning” factor).
So for example, in the present problem we could either</p>
<ul>
<li>Compare the supplements at each of the dose levels (3 tests total), or</li>
<li>Compare the dose levels within each of the supplement types (3 × 2 = 6 tests total).</li>
</ul>
<p>Frequently in practice, the context of the problem will dictate to the researcher which way makes the most sense.
We’ll provide code that performs both cases using the <code>emmeans</code> package.</p>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb146-1"><a href="multiple-factor-designed-experiments.html#cb146-1" aria-hidden="true" tabindex="-1"></a>tooth.mc1 <span class="ot">&lt;-</span> <span class="fu">emmeans</span>(tooth.fit, pairwise <span class="sc">~</span> <span class="fu">factor</span>(dose) <span class="sc">|</span> supp)</span>
<span id="cb146-2"><a href="multiple-factor-designed-experiments.html#cb146-2" aria-hidden="true" tabindex="-1"></a>tooth.mc2 <span class="ot">&lt;-</span> <span class="fu">emmeans</span>(tooth.fit, pairwise <span class="sc">~</span> supp <span class="sc">|</span> <span class="fu">factor</span>(dose) )</span>
<span id="cb146-3"><a href="multiple-factor-designed-experiments.html#cb146-3" aria-hidden="true" tabindex="-1"></a>tooth.mc1</span></code></pre></div>
<pre><code>## $emmeans
## supp = OJ:
##  dose emmean   SE df lower.CL upper.CL
##   0.5  13.23 1.15 54    10.93     15.5
##   1.0  22.70 1.15 54    20.40     25.0
##   2.0  26.06 1.15 54    23.76     28.4
## 
## supp = VC:
##  dose emmean   SE df lower.CL upper.CL
##   0.5   7.98 1.15 54     5.68     10.3
##   1.0  16.77 1.15 54    14.47     19.1
##   2.0  26.14 1.15 54    23.84     28.4
## 
## Confidence level used: 0.95 
## 
## $contrasts
## supp = OJ:
##  contrast estimate   SE df t.ratio p.value
##  0.5 - 1     -9.47 1.62 54  -5.831  &lt;.0001
##  0.5 - 2    -12.83 1.62 54  -7.900  &lt;.0001
##  1 - 2       -3.36 1.62 54  -2.069  0.1060
## 
## supp = VC:
##  contrast estimate   SE df t.ratio p.value
##  0.5 - 1     -8.79 1.62 54  -5.413  &lt;.0001
##  0.5 - 2    -18.16 1.62 54 -11.182  &lt;.0001
##  1 - 2       -9.37 1.62 54  -5.770  &lt;.0001
## 
## P value adjustment: tukey method for comparing a family of 3 estimates</code></pre>
<div class="sourceCode" id="cb148"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb148-1"><a href="multiple-factor-designed-experiments.html#cb148-1" aria-hidden="true" tabindex="-1"></a>tooth.mc2</span></code></pre></div>
<pre><code>## $emmeans
## dose = 0.5:
##  supp emmean   SE df lower.CL upper.CL
##  OJ    13.23 1.15 54    10.93     15.5
##  VC     7.98 1.15 54     5.68     10.3
## 
## dose = 1.0:
##  supp emmean   SE df lower.CL upper.CL
##  OJ    22.70 1.15 54    20.40     25.0
##  VC    16.77 1.15 54    14.47     19.1
## 
## dose = 2.0:
##  supp emmean   SE df lower.CL upper.CL
##  OJ    26.06 1.15 54    23.76     28.4
##  VC    26.14 1.15 54    23.84     28.4
## 
## Confidence level used: 0.95 
## 
## $contrasts
## dose = 0.5:
##  contrast estimate   SE df t.ratio p.value
##  OJ - VC      5.25 1.62 54   3.233  0.0021
## 
## dose = 1.0:
##  contrast estimate   SE df t.ratio p.value
##  OJ - VC      5.93 1.62 54   3.651  0.0006
## 
## dose = 2.0:
##  contrast estimate   SE df t.ratio p.value
##  OJ - VC     -0.08 1.62 54  -0.049  0.9609</code></pre>
<p>Here we see the output includes the estimates and confidence intervals for the means (while holding one factor fixed) and also includes the contrasts (comparisons) of one factor while holding the second factor constant.</p>
<p>At a dose level of 0.5 mg, ascorbic acid delivery via orange juice produces significantly larger mean tooth growth than does delivery via Vitamin C.
We determined this based on the the second set of output, where we see an adjusted <span class="math inline">\(p\)</span>-value of 0.0021 comparing orange juice with Vitamin C.
Similarly, at <code>dose=1.0</code>, there is still a difference but not at <code>dose=2.0</code>.</p>
<p>We can also use plotting features to graphically explore the factors while holding another factor constant.</p>
<div class="sourceCode" id="cb150"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb150-1"><a href="multiple-factor-designed-experiments.html#cb150-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(tooth.mc1)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ch3-19"></span>
<img src="introStatModeling_files/figure-html/ch3-19-1.png" alt="Graphical exploration of all treatments noting that the OJ supplement tends to result in higher tooth lengths than Vitamin C." width="70%" />
<p class="caption">
Figure 3.17: Graphical exploration of all treatments noting that the OJ supplement tends to result in higher tooth lengths than Vitamin C.
</p>
</div>
<p>Here we explore the performance of the dosage amounts conditioning (essentially faceting) on the delivery type.
Graphically we can see that the OJ method tends to have higher tooth lengths than Vitamin C for the low dosage levels of ascorbic acid.</p>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-R-gridExtra" class="csl-entry">
Auguie, B., <em>gridExtra: Miscellaneous Functions for "Grid" Graphics</em>, from <a href="https://CRAN.R-project.org/package=gridExtra">https://CRAN.R-project.org/package=gridExtra</a>, 2017.
</div>
<div id="ref-Crampton-1947" class="csl-entry">
Crampton, E. W., <span class="nocase">The Growth of the Odontoblasts of the Incisor Tooth as a Criterion of the Vitamin C Intake of the Guinea Pig: Five Figures</span>, <em>The Journal of Nutrition</em>, vol. <strong>33</strong>, no. 5, pp. 491–504, from <a href="https://doi.org/10.1093/jn/33.5.491">https://doi.org/10.1093/jn/33.5.491</a>, May 1947. DOI: <a href="https://doi.org/10.1093/jn/33.5.491">10.1093/jn/33.5.491</a>
</div>
<div id="ref-Fisher1935" class="csl-entry">
Fisher, R. A., <em><span class="nocase">The Design of Experiments</span></em>, Edinburgh: Oliver; Boyd, 1935.
</div>
<div id="ref-Hall1975" class="csl-entry">
Hall, S. M., Self-Control and Therapist Control in the Behavioral Treatment of Overweight Women, <em>Behaviour Research and Therapy</em>, vol. <strong>10</strong>, no. 1, pp. 59–68, 1972. DOI: <a href="https://doi.org/10.1016/0005-7967(72)90008-3">https://doi.org/10.1016/0005-7967(72)90008-3</a>
</div>
<div id="ref-ImmerHayesPowers1934" class="csl-entry">
Immer, F. R., Hayes, H. K. and Powers, L., Statistical Determination of Barley Varietal Adaptation1, <em>Agronomy Journal</em>, vol. <strong>26</strong>, no. 5, pp. 403–19, from <a href="https://acsess.onlinelibrary.wiley.com/doi/abs/10.2134/agronj1934.00021962002600050008x">https://acsess.onlinelibrary.wiley.com/doi/abs/10.2134/agronj1934.00021962002600050008x</a>, 1934. DOI: <a href="https://doi.org/10.2134/agronj1934.00021962002600050008x">https://doi.org/10.2134/agronj1934.00021962002600050008x</a>
</div>
<div id="ref-R-base" class="csl-entry">
R Core Team, <em>R: A Language and Environment for Statistical Computing</em>, Vienna, Austria: R Foundation for Statistical Computing, from <a href="https://www.R-project.org/">https://www.R-project.org/</a>, 2019.
</div>
<div id="ref-Walpole2007" class="csl-entry">
Walpole, R. E., Myers, R. H., Myers, S. L. and Ye, K., <em>Probability &amp; Statistics for Engineers and Scientists</em>, Upper Saddle River: Pearson Education, 2007.
</div>
<div id="ref-WeissText" class="csl-entry">
Weiss, N. A., <em>Introductory Statistics</em>, Pearson Education, 2012.
</div>
<div id="ref-Younes1994" class="csl-entry">
Younes, S. S., Highway Construction Safety and the Aging Driver: Detection and Legibility Distances of Construction Warning Signs, PhD thesis, Arizona State University, 1194.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction-to-statistical-modeling-and-designed-experiments.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="advanced-designs.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["introStatModeling.pdf", "introStatModeling.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
